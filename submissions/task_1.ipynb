{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8vS5GgzSmhIn",
        "outputId": "7ed6153b-cdc0-4259-c85e-c2fd83116353"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow version: 2.19.0\n",
            "keras 3.10.0\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, models, regularizers\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(\"TensorFlow version:\", tf.__version__)\n",
        "print(\"keras\", keras.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C55EmxaXoZDL",
        "outputId": "b1ad95ff-d296-41eb-eddb-102b1e822fc1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "\u001b[1m29515/29515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "\u001b[1m26421880/26421880\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "\u001b[1m5148/5148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "\u001b[1m4422102/4422102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "X_train shape: (54000, 28, 28)\n",
            "y_train shape: (54000,)\n",
            "Test: (10000, 28, 28) (10000,)\n"
          ]
        }
      ],
      "source": [
        "(X_train_full, y_train_full), (X_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
        "X_train_full = X_train_full/255.0\n",
        "X_test = X_test/255.0\n",
        "\n",
        "X_valid, X_train = X_train_full[:6000], X_train_full[6000:]\n",
        "y_valid, y_train = y_train_full[:6000], y_train_full[6000:]\n",
        "\n",
        "print(\"X_train shape:\", X_train.shape)\n",
        "print(\"y_train shape:\", y_train.shape)\n",
        "print(\"Test:\", X_test.shape, y_test.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "0g_N6lkTpVQ8",
        "outputId": "9aad4160-0d21-44ef-afe3-8ce8223f4a2f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m784\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m)            │       \u001b[38;5;34m235,500\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │        \u001b[38;5;34m30,100\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │         \u001b[38;5;34m1,010\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">235,500</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">30,100</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,010</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m266,610\u001b[0m (1.02 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">266,610</span> (1.02 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m266,610\u001b[0m (1.02 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">266,610</span> (1.02 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "#mlp model\n",
        "mlp_model = keras.Sequential([\n",
        "    keras.layers.Flatten(input_shape=[28, 28]),\n",
        "    keras.layers.Dense(300, activation=\"relu\"),\n",
        "    keras.layers.Dense(100, activation=\"relu\"),\n",
        "    keras.layers.Dense(10, activation=\"softmax\")\n",
        "])\n",
        "\n",
        "mlp_model.compile(\n",
        "    loss=\"sparse_categorical_crossentropy\",\n",
        "    optimizer=\"adam\",\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "\n",
        "mlp_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "33dl9mcTqipt",
        "outputId": "ad893982-0f1c-41af-d864-c4af826fdf16"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.7828 - loss: 0.6149 - val_accuracy: 0.8640 - val_loss: 0.3804\n",
            "Epoch 2/30\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.8643 - loss: 0.3736 - val_accuracy: 0.8762 - val_loss: 0.3389\n",
            "Epoch 3/30\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.8778 - loss: 0.3314 - val_accuracy: 0.8745 - val_loss: 0.3491\n",
            "Epoch 4/30\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.8857 - loss: 0.3053 - val_accuracy: 0.8807 - val_loss: 0.3356\n",
            "Epoch 5/30\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.8943 - loss: 0.2829 - val_accuracy: 0.8803 - val_loss: 0.3249\n",
            "Epoch 6/30\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 7ms/step - accuracy: 0.8989 - loss: 0.2664 - val_accuracy: 0.8913 - val_loss: 0.3065\n",
            "Epoch 7/30\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.9053 - loss: 0.2559 - val_accuracy: 0.8867 - val_loss: 0.3122\n",
            "Epoch 8/30\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.9054 - loss: 0.2462 - val_accuracy: 0.8912 - val_loss: 0.3025\n",
            "Epoch 9/30\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.9134 - loss: 0.2293 - val_accuracy: 0.8863 - val_loss: 0.3151\n",
            "Epoch 10/30\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.9142 - loss: 0.2238 - val_accuracy: 0.8765 - val_loss: 0.3439\n",
            "Epoch 11/30\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.9186 - loss: 0.2136 - val_accuracy: 0.8913 - val_loss: 0.3185\n",
            "Epoch 12/30\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.9229 - loss: 0.2047 - val_accuracy: 0.8912 - val_loss: 0.3128\n",
            "Epoch 13/30\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - accuracy: 0.9246 - loss: 0.1985 - val_accuracy: 0.8978 - val_loss: 0.3053\n",
            "Epoch 14/30\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.9282 - loss: 0.1885 - val_accuracy: 0.8925 - val_loss: 0.3240\n",
            "Epoch 15/30\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.9289 - loss: 0.1834 - val_accuracy: 0.8978 - val_loss: 0.3299\n",
            "Epoch 16/30\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.9329 - loss: 0.1758 - val_accuracy: 0.8877 - val_loss: 0.3569\n",
            "Epoch 17/30\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.9317 - loss: 0.1797 - val_accuracy: 0.8930 - val_loss: 0.3397\n",
            "Epoch 18/30\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.9348 - loss: 0.1721 - val_accuracy: 0.8938 - val_loss: 0.3522\n",
            "Epoch 19/30\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.9372 - loss: 0.1655 - val_accuracy: 0.8967 - val_loss: 0.3363\n",
            "Epoch 20/30\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.9408 - loss: 0.1548 - val_accuracy: 0.8895 - val_loss: 0.3599\n",
            "Epoch 21/30\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.9403 - loss: 0.1541 - val_accuracy: 0.8967 - val_loss: 0.3566\n",
            "Epoch 22/30\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.9422 - loss: 0.1488 - val_accuracy: 0.8860 - val_loss: 0.4068\n",
            "Epoch 23/30\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.9428 - loss: 0.1470 - val_accuracy: 0.8910 - val_loss: 0.4181\n",
            "Epoch 24/30\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.9469 - loss: 0.1423 - val_accuracy: 0.8922 - val_loss: 0.4155\n",
            "Epoch 25/30\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.9487 - loss: 0.1360 - val_accuracy: 0.8962 - val_loss: 0.3846\n",
            "Epoch 26/30\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.9457 - loss: 0.1391 - val_accuracy: 0.8912 - val_loss: 0.3998\n",
            "Epoch 27/30\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.9493 - loss: 0.1319 - val_accuracy: 0.8957 - val_loss: 0.4080\n",
            "Epoch 28/30\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.9519 - loss: 0.1256 - val_accuracy: 0.8952 - val_loss: 0.4323\n",
            "Epoch 29/30\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.9534 - loss: 0.1223 - val_accuracy: 0.8965 - val_loss: 0.4198\n",
            "Epoch 30/30\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.9531 - loss: 0.1226 - val_accuracy: 0.8933 - val_loss: 0.4273\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8919 - loss: 0.4642\n",
            "Test accuracy: 88.90%\n"
          ]
        }
      ],
      "source": [
        "history_mlp = mlp_model.fit(\n",
        "    X_train, y_train,\n",
        "    epochs=30,\n",
        "    validation_data=(X_valid, y_valid)\n",
        ")\n",
        "\n",
        "test_loss, test_accuracy = mlp_model.evaluate(X_test, y_test)\n",
        "print(f\"Test accuracy: {test_accuracy * 100:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 440
        },
        "id": "T4d5edRarT2U",
        "outputId": "537dfc84-a436-44b7-908e-e41e94327c36"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m320\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3136\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m401,536\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │         \u001b[38;5;34m1,290\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3136</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">401,536</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,290</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m421,642\u001b[0m (1.61 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">421,642</span> (1.61 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m421,642\u001b[0m (1.61 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">421,642</span> (1.61 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "X_train_cnn = X_train[..., np.newaxis]\n",
        "X_valid_cnn = X_valid[..., np.newaxis]\n",
        "X_test_cnn = X_test[..., np.newaxis]\n",
        "\n",
        "cnn_model =  keras.Sequential([\n",
        "    layers.Conv2D(32, (3, 3), activation=\"relu\", padding=\"same\", input_shape=(28, 28, 1)),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(64, (3, 3), activation=\"relu\", padding=\"same\"),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(128, activation=\"relu\"),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(10, activation=\"softmax\")\n",
        "])\n",
        "\n",
        "cnn_model.compile(\n",
        "    optimizer=\"adam\",\n",
        "    loss=\"sparse_categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "cnn_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LvpJQaFnsy9N",
        "outputId": "d729a636-e5a3-4ebf-acfa-e5504c9316bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/12\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 44ms/step - accuracy: 0.7431 - loss: 0.7150 - val_accuracy: 0.8882 - val_loss: 0.3213\n",
            "Epoch 2/12\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 44ms/step - accuracy: 0.8712 - loss: 0.3601 - val_accuracy: 0.8985 - val_loss: 0.2712\n",
            "Epoch 3/12\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 44ms/step - accuracy: 0.8897 - loss: 0.2995 - val_accuracy: 0.9142 - val_loss: 0.2476\n",
            "Epoch 4/12\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 44ms/step - accuracy: 0.9044 - loss: 0.2681 - val_accuracy: 0.9158 - val_loss: 0.2251\n",
            "Epoch 5/12\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 43ms/step - accuracy: 0.9130 - loss: 0.2422 - val_accuracy: 0.9187 - val_loss: 0.2196\n",
            "Epoch 6/12\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 46ms/step - accuracy: 0.9206 - loss: 0.2186 - val_accuracy: 0.9227 - val_loss: 0.2078\n",
            "Epoch 7/12\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 48ms/step - accuracy: 0.9277 - loss: 0.2031 - val_accuracy: 0.9202 - val_loss: 0.2069\n",
            "Epoch 8/12\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 46ms/step - accuracy: 0.9289 - loss: 0.1917 - val_accuracy: 0.9192 - val_loss: 0.2230\n",
            "Epoch 9/12\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 45ms/step - accuracy: 0.9375 - loss: 0.1706 - val_accuracy: 0.9232 - val_loss: 0.2120\n",
            "Epoch 10/12\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 46ms/step - accuracy: 0.9401 - loss: 0.1632 - val_accuracy: 0.9245 - val_loss: 0.2221\n",
            "Epoch 11/12\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 47ms/step - accuracy: 0.9429 - loss: 0.1504 - val_accuracy: 0.9243 - val_loss: 0.2201\n",
            "Epoch 12/12\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 45ms/step - accuracy: 0.9474 - loss: 0.1411 - val_accuracy: 0.9272 - val_loss: 0.2272\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - accuracy: 0.9223 - loss: 0.2588\n",
            "Test accuracy (CNN): 0.921500\n"
          ]
        }
      ],
      "source": [
        "history_cnn = cnn_model.fit(\n",
        "    X_train_cnn, y_train,\n",
        "    epochs = 12,\n",
        "    validation_data=(X_valid_cnn, y_valid)\n",
        ")\n",
        "\n",
        "\n",
        "test_loss_cnn, test_accuracy_cnn = cnn_model.evaluate(X_test_cnn, y_test)\n",
        "print(f\"Test accuracy (CNN): {test_accuracy_cnn:4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vHqrUASqycMY"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
        "\n",
        "def build_mlp(activation='relu', optimizer='adam', dropout_rate=0.0, l2_reg=0.0):\n",
        "  model = keras.Sequential([\n",
        "      layers.Flatten(input_shape=[28, 28]),\n",
        "      layers.Dense(300, activation=activation,\n",
        "                   kernel_regularizer = regularizers.l2(l2_reg) if l2_reg > 0.0 else None\n",
        "                   ),\n",
        "      layers.Dropout(dropout_rate),\n",
        "      layers.Dense(100, activation=activation,\n",
        "                   kernel_regularizer = regularizers.l2(l2_reg) if l2_reg > 0.0 else None\n",
        "                   ),\n",
        "      layers.Dropout(dropout_rate),\n",
        "      layers.Dense(10, activation='softmax')\n",
        "  ])\n",
        "\n",
        "  model.compile(\n",
        "      loss='sparse_categorical_crossentropy',\n",
        "      optimizer=optimizer,\n",
        "      metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "  return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bvuCKpwt0Qi3",
        "outputId": "47a7153a-14ee-4547-b4bf-86d669b5a165"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "n----Training with activation = relu---\n",
            "Validation accuracy with relu activation: 0.8753\n",
            "n----Training with activation = tanh---\n",
            "Validation accuracy with tanh activation: 0.8817\n",
            "n----Training with activation = sigmoid---\n",
            "Validation accuracy with sigmoid activation: 0.8768\n",
            "{'relu': 0.875333309173584, 'tanh': 0.8816666603088379, 'sigmoid': 0.8768333196640015}\n"
          ]
        }
      ],
      "source": [
        "from re import VERBOSE\n",
        "activations =  ['relu', 'tanh', 'sigmoid']\n",
        "results_activations = {}\n",
        "\n",
        "for act in activations:\n",
        "  print(f\"n----Training with activation = {act}---\")\n",
        "  model = build_mlp(activation=act)\n",
        "  history = model.fit(\n",
        "      X_train, y_train,\n",
        "      epochs=5, batch_size=128,\n",
        "      validation_data=(X_valid, y_valid),\n",
        "      verbose=0\n",
        "  )\n",
        "\n",
        "  val_acc =  history.history['val_accuracy'][-1]\n",
        "  results_activations[act] = val_acc\n",
        "  print(f\"Validation accuracy with {act} activation: {val_acc:.4f}\")\n",
        "\n",
        "print(results_activations)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eb_ZXjWA1l5_",
        "outputId": "c127eb1a-789e-4d5c-89c1-1deb1d440938"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training with optimizer: adam\n",
            "Training with optimizer: sgd\n",
            "Training with optimizer: rmsprop\n",
            "{'adam': 0.8806666731834412, 'sgd': 0.8771666884422302, 'rmsprop': 0.8684999942779541}\n"
          ]
        }
      ],
      "source": [
        "optimizers = {\n",
        "    'adam' : Adam(learning_rate=0.001),\n",
        "    'sgd' : SGD(learning_rate=0.01, momentum=0.9),\n",
        "    'rmsprop' : RMSprop(learning_rate=0.001)\n",
        "}\n",
        "\n",
        "results_opt = {}\n",
        "\n",
        "for name, opt in optimizers.items():\n",
        "  print(f\"Training with optimizer: {name}\")\n",
        "  model = build_mlp(activation='relu', optimizer=opt)\n",
        "  history = model.fit(X_train, y_train,\n",
        "                     epochs=5, batch_size=128,\n",
        "                      validation_data=(X_valid, y_valid),\n",
        "                      verbose=0\n",
        "                      )\n",
        "  val_acc = history.history['val_accuracy'][-1]\n",
        "  results_opt[name] = val_acc\n",
        "\n",
        "print(results_opt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K-4PrA5J2qjW",
        "outputId": "53301ce9-b147-43d0-dcd7-65bd8beec72f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "---Training with dropout_rate = 0.0 and l2_reg = 0.0---\n",
            "Validation accuracy with dropout_rate=0.0, l2_reg=0.0: 0.8835\n",
            "\n",
            "---Training with dropout_rate = 0.3 and l2_reg = 0.0---\n",
            "Validation accuracy with dropout_rate=0.3, l2_reg=0.0: 0.8765\n",
            "\n",
            "---Training with dropout_rate = 0.5 and l2_reg = 0.001---\n",
            "Validation accuracy with dropout_rate=0.5, l2_reg=0.001: 0.8560\n",
            "{'dropout_rate=0.0, l2_reg=0.0': 0.8834999799728394, 'dropout_rate=0.3, l2_reg=0.0': 0.8765000104904175, 'dropout_rate=0.5, l2_reg=0.001': 0.8560000061988831}\n"
          ]
        }
      ],
      "source": [
        "regularization_settings = [\n",
        "    {'dropout_rate' : 0.0, 'l2_reg': 0.0},\n",
        "    {'dropout_rate' : 0.3, 'l2_reg': 0.0},\n",
        "    {'dropout_rate' : 0.5, 'l2_reg': 0.001},\n",
        "]\n",
        "\n",
        "results_reg = {}\n",
        "\n",
        "for settings in regularization_settings:\n",
        "  dr, l2r = settings['dropout_rate'], settings['l2_reg']\n",
        "  print(f\"\\n---Training with dropout_rate = {dr} and l2_reg = {l2r}---\")\n",
        "  model = build_mlp(dropout_rate=dr, l2_reg=l2r)\n",
        "  history = model.fit(X_train, y_train,\n",
        "                      epochs=5, batch_size=128,\n",
        "                      validation_data=(X_valid, y_valid),\n",
        "                      verbose=0\n",
        "                      )\n",
        "  val_acc = history.history['val_accuracy'][-1]\n",
        "  results_reg[f\"dropout_rate={dr}, l2_reg={l2r}\"] = val_acc\n",
        "  print(f\"Validation accuracy with dropout_rate={dr}, l2_reg={l2r}: {val_acc:.4f}\")\n",
        "\n",
        "print(results_reg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g8-gBKrS4MfF",
        "outputId": "8aad29b4-e391-4ae7-b987-e9f484307433"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "n-----Training with depth = 1 hidden layers-----\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<>:29: SyntaxWarning: invalid escape sequence '\\ '\n",
            "<>:29: SyntaxWarning: invalid escape sequence '\\ '\n",
            "/tmp/ipython-input-430911969.py:29: SyntaxWarning: invalid escape sequence '\\ '\n",
            "  print(\"n\\ Depth comparison:\", results_depth)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation accuracy with 1 hidden layers: 0.8808\n",
            "n-----Training with depth = 2 hidden layers-----\n",
            "Validation accuracy with 2 hidden layers: 0.8832\n",
            "n-----Training with depth = 3 hidden layers-----\n",
            "Validation accuracy with 3 hidden layers: 0.8768\n",
            "n-----Training with depth = 4 hidden layers-----\n",
            "Validation accuracy with 4 hidden layers: 0.8837\n",
            "n\\ Depth comparison: {1: 0.8808333277702332, 2: 0.8831666707992554, 3: 0.8768333196640015, 4: 0.8836666941642761}\n"
          ]
        }
      ],
      "source": [
        "def build_mlp_depth(depth=2):\n",
        "  model = keras.Sequential([layers.Flatten(input_shape=[28, 28])])\n",
        "  for i in range(depth):\n",
        "    model.add(layers.Dense(128, activation='relu'))\n",
        "  model.add(layers.Dense(10, activation='softmax'))\n",
        "  model.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "                optimizer='adam',\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "  return model\n",
        "\n",
        "\n",
        "\n",
        "depths = [1, 2, 3, 4]\n",
        "results_depth = {}\n",
        "\n",
        "for d in depths:\n",
        "  print(f\"n-----Training with depth = {d} hidden layers-----\")\n",
        "  model = build_mlp_depth(depth=d)\n",
        "  history = model.fit(X_train, y_train,\n",
        "                      epochs=5, batch_size=128,\n",
        "                      validation_data=(X_valid, y_valid),\n",
        "                      verbose=0\n",
        "  )\n",
        "  val_acc = history.history['val_accuracy'][-1]\n",
        "  results_depth[d] = val_acc\n",
        "  print(f\"Validation accuracy with {d} hidden layers: {val_acc:.4f}\")\n",
        "\n",
        "print(\"n\\ Depth comparison:\", results_depth)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0xISxNMj5olc",
        "outputId": "268eeb9c-6c22-44a8-9e07-1d613a17b221"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- CNN with filters (32,64), dropout=0.5 ---\n",
            "Validation accuracy: 0.9105\n",
            "\n",
            "--- CNN with filters (64,128), dropout=0.3 ---\n",
            "Validation accuracy: 0.9255\n",
            "\n",
            "--- CNN with filters (16,32), dropout=0.0 ---\n",
            "Validation accuracy: 0.9057\n",
            "\n",
            "CNN configuration comparison: {\"{'filters1': 32, 'filters2': 64, 'dropout_rate': 0.5}\": 0.9104999899864197, \"{'filters1': 64, 'filters2': 128, 'dropout_rate': 0.3}\": 0.9254999756813049, \"{'filters1': 16, 'filters2': 32, 'dropout_rate': 0.0}\": 0.9056666493415833}\n"
          ]
        }
      ],
      "source": [
        "\n",
        "def build_cnn(filters1=32, filters2=64, dropout_rate=0.5, activation='relu'):\n",
        "    model = keras.Sequential([\n",
        "        layers.Conv2D(filters1, (3,3), activation=activation, padding='same', input_shape=(28,28,1)),\n",
        "        layers.MaxPooling2D((2,2)),\n",
        "        layers.Conv2D(filters2, (3,3), activation=activation, padding='same'),\n",
        "        layers.MaxPooling2D((2,2)),\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(128, activation=activation),\n",
        "        layers.Dropout(dropout_rate),\n",
        "        layers.Dense(10, activation='softmax')\n",
        "    ])\n",
        "    model.compile(\n",
        "        optimizer='adam',\n",
        "        loss='sparse_categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "    return model\n",
        "\n",
        "cnn_settings = [\n",
        "    {'filters1': 32, 'filters2': 64, 'dropout_rate': 0.5},\n",
        "    {'filters1': 64, 'filters2': 128, 'dropout_rate': 0.3},\n",
        "    {'filters1': 16, 'filters2': 32, 'dropout_rate': 0.0}\n",
        "]\n",
        "\n",
        "results_cnn = {}\n",
        "\n",
        "for s in cnn_settings:\n",
        "    print(f\"\\n--- CNN with filters ({s['filters1']},{s['filters2']}), dropout={s['dropout_rate']} ---\")\n",
        "    model = build_cnn(**s)\n",
        "    history = model.fit(\n",
        "        X_train_cnn, y_train,\n",
        "        epochs=5, batch_size=128,\n",
        "        validation_data=(X_valid_cnn, y_valid),\n",
        "        verbose=0\n",
        "    )\n",
        "    val_acc = history.history['val_accuracy'][-1]\n",
        "    results_cnn[str(s)] = val_acc\n",
        "    print(f\"Validation accuracy: {val_acc:.4f}\")\n",
        "\n",
        "print(\"\\nCNN configuration comparison:\", results_cnn)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HbwMOEBJ5y67",
        "outputId": "7fa14f76-7089-4fc8-b58d-d4209a4e60b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Summary of MLP Experiments ===\n",
            "Activation: {'relu': 0.875333309173584, 'tanh': 0.8816666603088379, 'sigmoid': 0.8768333196640015}\n",
            "Optimizers: {'adam': 0.8806666731834412, 'sgd': 0.8771666884422302, 'rmsprop': 0.8684999942779541}\n",
            "Regularization: {'dropout_rate=0.0, l2_reg=0.0': 0.8834999799728394, 'dropout_rate=0.3, l2_reg=0.0': 0.8765000104904175, 'dropout_rate=0.5, l2_reg=0.001': 0.8560000061988831}\n",
            "Depth: {1: 0.8808333277702332, 2: 0.8831666707992554, 3: 0.8768333196640015, 4: 0.8836666941642761}\n",
            "\n",
            "=== CNN Experiments ===\n",
            "{\"{'filters1': 32, 'filters2': 64, 'dropout_rate': 0.5}\": 0.9104999899864197, \"{'filters1': 64, 'filters2': 128, 'dropout_rate': 0.3}\": 0.9254999756813049, \"{'filters1': 16, 'filters2': 32, 'dropout_rate': 0.0}\": 0.9056666493415833}\n"
          ]
        }
      ],
      "source": [
        "\n",
        "print(\"=== Summary of MLP Experiments ===\")\n",
        "print(\"Activation:\", results_activations)\n",
        "print(\"Optimizers:\", results_opt)\n",
        "print(\"Regularization:\", results_reg)\n",
        "print(\"Depth:\", results_depth)\n",
        "\n",
        "print(\"\\n=== CNN Experiments ===\")\n",
        "print(results_cnn)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G_tOFRrQ__eO",
        "outputId": "ca83812a-54dc-4d7e-e7b0-249b61ebd7de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "\u001b[1m170498071/170498071\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 0us/step\n",
            "Train: (45000, 32, 32, 3) (45000, 1)\n",
            "Valid: (5000, 32, 32, 3) (5000, 1)\n",
            "Test : (10000, 32, 32, 3) (10000, 1)\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Load dataset\n",
        "(X_train_full, y_train_full), (X_test, y_test) = cifar10.load_data()\n",
        "\n",
        "# Normalize to [0,1]\n",
        "X_train_full = X_train_full.astype('float32') / 255.0\n",
        "X_test = X_test.astype('float32') / 255.0\n",
        "\n",
        "# Create validation split (10% of training)\n",
        "num_val = int(0.1 * X_train_full.shape[0])\n",
        "X_valid, X_train = X_train_full[:num_val], X_train_full[num_val:]\n",
        "y_valid, y_train = y_train_full[:num_val], y_train_full[num_val:]\n",
        "\n",
        "print(\"Train:\", X_train.shape, y_train.shape)\n",
        "print(\"Valid:\", X_valid.shape, y_valid.shape)\n",
        "print(\"Test :\", X_test.shape, y_test.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wXhp4b7aAOHz"
      },
      "outputs": [],
      "source": [
        "\n",
        "def build_mlp_cifar(activation='relu', dropout_rate=0.3):\n",
        "  model = keras.Sequential([\n",
        "        layers.Flatten(input_shape=(32, 32, 3)),\n",
        "        layers.Dense(512, activation=activation),\n",
        "        layers.Dropout(dropout_rate),\n",
        "        layers.Dense(256, activation=activation),\n",
        "        layers.Dropout(dropout_rate),\n",
        "        layers.Dense(10, activation='softmax')\n",
        "    ])\n",
        "\n",
        "  model.compile(\n",
        "        optimizer='adam',\n",
        "        loss='sparse_categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "\n",
        "  return model\n",
        "\n",
        "\n",
        "def build_cnn_cifar(filters1=32, filters2=64, dropout_rate=0.5, activation='relu'):\n",
        "    model = keras.Sequential([\n",
        "        layers.Conv2D(filters1, (3,3), activation=activation, padding='same', input_shape=(32,32,3)),\n",
        "        layers.Conv2D(filters1, (3,3), activation=activation, padding='same'),\n",
        "        layers.MaxPooling2D((2,2)),\n",
        "        layers.Conv2D(filters2, (3,3), activation=activation, padding='same'),\n",
        "        layers.Conv2D(filters2, (3,3), activation=activation, padding='same'),\n",
        "        layers.MaxPooling2D((2,2)),\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(256, activation=activation),\n",
        "        layers.Dropout(dropout_rate),\n",
        "        layers.Dense(10, activation='softmax')\n",
        "    ])\n",
        "    model.compile(\n",
        "        optimizer='adam',\n",
        "        loss='sparse_categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q3k5ETHWAWW8",
        "outputId": "ed2dc109-b0fc-4831-f3df-095ffd121abc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 46ms/step - accuracy: 0.2098 - loss: 2.2056 - val_accuracy: 0.3368 - val_loss: 1.8357\n",
            "Epoch 2/15\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 43ms/step - accuracy: 0.3091 - loss: 1.8979 - val_accuracy: 0.3690 - val_loss: 1.7709\n",
            "Epoch 3/15\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 44ms/step - accuracy: 0.3221 - loss: 1.8480 - val_accuracy: 0.3966 - val_loss: 1.7244\n",
            "Epoch 4/15\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 43ms/step - accuracy: 0.3385 - loss: 1.8144 - val_accuracy: 0.3904 - val_loss: 1.7116\n",
            "Epoch 5/15\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 43ms/step - accuracy: 0.3565 - loss: 1.7916 - val_accuracy: 0.3988 - val_loss: 1.7058\n",
            "Epoch 6/15\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 43ms/step - accuracy: 0.3579 - loss: 1.7694 - val_accuracy: 0.4112 - val_loss: 1.6931\n",
            "Epoch 7/15\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 43ms/step - accuracy: 0.3644 - loss: 1.7560 - val_accuracy: 0.4160 - val_loss: 1.6672\n",
            "Epoch 8/15\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 43ms/step - accuracy: 0.3725 - loss: 1.7367 - val_accuracy: 0.4274 - val_loss: 1.6482\n",
            "Epoch 9/15\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 42ms/step - accuracy: 0.3798 - loss: 1.7110 - val_accuracy: 0.4202 - val_loss: 1.6477\n",
            "Epoch 10/15\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 43ms/step - accuracy: 0.3764 - loss: 1.7286 - val_accuracy: 0.4242 - val_loss: 1.6346\n",
            "Epoch 11/15\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 44ms/step - accuracy: 0.3845 - loss: 1.6969 - val_accuracy: 0.4162 - val_loss: 1.6699\n",
            "Epoch 12/15\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 43ms/step - accuracy: 0.3886 - loss: 1.6950 - val_accuracy: 0.4268 - val_loss: 1.6321\n",
            "Epoch 13/15\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 42ms/step - accuracy: 0.3880 - loss: 1.6983 - val_accuracy: 0.4362 - val_loss: 1.6303\n",
            "Epoch 14/15\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 45ms/step - accuracy: 0.3939 - loss: 1.6800 - val_accuracy: 0.4280 - val_loss: 1.6395\n",
            "Epoch 15/15\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 42ms/step - accuracy: 0.3950 - loss: 1.6755 - val_accuracy: 0.4364 - val_loss: 1.6172\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.4334 - loss: 1.6200\n",
            "Test accuracy (MLP on CIFAR-10): 0.4288\n"
          ]
        }
      ],
      "source": [
        "mlp_cifar = build_mlp_cifar(activation='relu', dropout_rate=0.3)\n",
        "\n",
        "history_mlp_cifar = mlp_cifar.fit(\n",
        "    X_train, y_train,\n",
        "    epochs=15,\n",
        "    batch_size=128,\n",
        "    validation_data=(X_valid, y_valid)\n",
        ")\n",
        "\n",
        "test_loss_mlp, test_acc_mlp = mlp_cifar.evaluate(X_test, y_test)\n",
        "print(f\"Test accuracy (MLP on CIFAR-10): {test_acc_mlp:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RuECgqgdAdzl",
        "outputId": "ee227b97-6ece-4030-de55-043de9c7ea86"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m726s\u001b[0m 2s/step - accuracy: 0.3508 - loss: 1.7676 - val_accuracy: 0.6112 - val_loss: 1.0871\n",
            "Epoch 2/15\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m734s\u001b[0m 2s/step - accuracy: 0.6281 - loss: 1.0571 - val_accuracy: 0.7018 - val_loss: 0.8603\n",
            "Epoch 3/15\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m741s\u001b[0m 2s/step - accuracy: 0.7107 - loss: 0.8220 - val_accuracy: 0.7252 - val_loss: 0.7961\n",
            "Epoch 4/15\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m713s\u001b[0m 2s/step - accuracy: 0.7612 - loss: 0.6785 - val_accuracy: 0.7434 - val_loss: 0.7311\n",
            "Epoch 5/15\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m734s\u001b[0m 2s/step - accuracy: 0.8090 - loss: 0.5538 - val_accuracy: 0.7646 - val_loss: 0.6940\n",
            "Epoch 6/15\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m731s\u001b[0m 2s/step - accuracy: 0.8434 - loss: 0.4422 - val_accuracy: 0.7722 - val_loss: 0.7038\n",
            "Epoch 7/15\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m723s\u001b[0m 2s/step - accuracy: 0.8740 - loss: 0.3622 - val_accuracy: 0.7710 - val_loss: 0.7514\n",
            "Epoch 8/15\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m724s\u001b[0m 2s/step - accuracy: 0.8961 - loss: 0.2943 - val_accuracy: 0.7796 - val_loss: 0.7484\n",
            "Epoch 9/15\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m761s\u001b[0m 2s/step - accuracy: 0.9162 - loss: 0.2334 - val_accuracy: 0.7790 - val_loss: 0.7392\n",
            "Epoch 10/15\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m737s\u001b[0m 2s/step - accuracy: 0.9338 - loss: 0.1842 - val_accuracy: 0.7834 - val_loss: 0.8211\n",
            "Epoch 11/15\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m711s\u001b[0m 2s/step - accuracy: 0.9411 - loss: 0.1602 - val_accuracy: 0.7822 - val_loss: 0.8405\n",
            "Epoch 12/15\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m737s\u001b[0m 2s/step - accuracy: 0.9483 - loss: 0.1481 - val_accuracy: 0.7832 - val_loss: 0.8984\n",
            "Epoch 13/15\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m710s\u001b[0m 2s/step - accuracy: 0.9560 - loss: 0.1224 - val_accuracy: 0.7826 - val_loss: 0.9398\n",
            "Epoch 14/15\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m744s\u001b[0m 2s/step - accuracy: 0.9609 - loss: 0.1136 - val_accuracy: 0.7834 - val_loss: 0.9324\n",
            "Epoch 15/15\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m715s\u001b[0m 2s/step - accuracy: 0.9599 - loss: 0.1152 - val_accuracy: 0.7814 - val_loss: 1.0247\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 134ms/step - accuracy: 0.7732 - loss: 1.0668\n",
            "Test accuracy (CNN on CIFAR-10): 0.7736\n"
          ]
        }
      ],
      "source": [
        "cnn_cifar = build_cnn_cifar(filters1=64, filters2=128, dropout_rate=0.3)\n",
        "\n",
        "history_cnn_cifar = cnn_cifar.fit(\n",
        "    X_train, y_train,\n",
        "    epochs=15,\n",
        "    batch_size=128,\n",
        "    validation_data=(X_valid, y_valid)\n",
        ")\n",
        "\n",
        "test_loss_cnn, test_acc_cnn = cnn_cifar.evaluate(X_test, y_test)\n",
        "print(f\"Test accuracy (CNN on CIFAR-10): {test_acc_cnn:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AUJ4CCrsBfw5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ad50128-435f-49a5-c9aa-5d9d49378b37"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x500 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAArMAAAHWCAYAAABkNgFvAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAZ0FJREFUeJzt3Xd4U2X/BvA7Sdu06d6LLqBSRim7AiqgIENBUECwMlVeZIv6MmQICrhAZAjqD8FRtqD4qiAWBdlILZuySgt0U7p3cn5/pA0NaUvTdXLa+3Nd50rynHNyvkkDvfvkOc+RCYIggIiIiIhIguRiF0BEREREVF0Ms0REREQkWQyzRERERCRZDLNEREREJFkMs0REREQkWQyzRERERCRZDLNEREREJFkMs0REREQkWQyzRERERCRZDLNEhJs3b0Imk2HTpk26tnfffRcymaxK+8tkMrz77ru1WlPPnj3Rs2fPWn1OIiJqeBhmiSRm0KBBUKlUyMrKqnCbsLAwWFhY4O7du/VYmfEuXryId999Fzdv3hS7lHL9+uuvkMlk8PLygkajEbscqkBSUhLeeustBAUFQaVSwdraGh07dsT777+P9PR03XY9e/ZEmzZt9Pb19/eHTCYrd8nPz9dtp1ar4eXlBZlMht9++63cOkr/ACxdzM3N4e/vj2nTpunVUZno6Gi88cYb6NatGywtLSGTySr997Fnzx506NABlpaW8PX1xcKFC1FcXFylYxE1FGZiF0BExgkLC8PPP/+M3bt3Y/To0Qbrc3Nz8dNPP6Ffv35wdnau9nHmzZuH2bNn16TUh7p48SIWLVqEnj17wt/fX2/d77//XqfHrorw8HD4+/vj5s2bOHDgAHr37i12SfSAU6dOYcCAAcjOzsbLL7+Mjh07AgD++ecffPDBBzh06NBDP0vt2rXDm2++adBuYWGhu3/gwAEkJCTA398f4eHh6N+/f4XPt27dOtjY2CAnJwcRERFYvXo1IiMjcfjw4Ye+nmPHjmHVqlVo1aoVWrZsiaioqAq3/e233zB48GD07NkTq1evxrlz5/D+++8jOTkZ69ate+ixiBoKhlkiiRk0aBBsbW2xefPmcsPsTz/9hJycHISFhdXoOGZmZjAzE++/iLJBQgw5OTn46aefsGzZMmzcuBHh4eEmG2ZzcnJgbW0tdhn1Lj09HUOGDIFCocC///6LoKAgvfVLlizBV1999dDn8fb2xssvv1zpNt9//z06dOiAMWPGYO7cuZW+50OHDoWLiwsA4D//+Q9GjBiBbdu24eTJk+jSpUulxxk0aBDS09Nha2uLTz75pNIw+9Zbb6Ft27b4/fffdf9W7ezssHTpUkyfPt3g/SBqqDjMgEhirKys8PzzzyMiIgLJyckG6zdv3gxbW1sMGjQIaWlpeOuttxAcHAwbGxvY2dmhf//+OHPmzEOPU96Y2YKCArzxxhtwdXXVHeP27dsG+8bGxmLSpElo0aIFrKys4OzsjGHDhul9Xbpp0yYMGzYMANCrVy/dV7N//fUXgPLHzCYnJ+OVV16Bu7s7LC0tERISgm+++UZvm9Lxv5988gm+/PJLNGvWDEqlEp07d8apU6ce+rpL7d69G3l5eRg2bBhGjBiBXbt26X3tXCo/Px/vvvsuHnnkEVhaWsLT0xPPP/88rl+/rttGo9Hgs88+Q3BwMCwtLeHq6op+/frhn3/+0au57JjlUg+ORy79uVy8eBEvvfQSHB0d8dhjjwEAzp49i7Fjx6Jp06awtLSEh4cHxo8fX+5wkzt37uCVV16Bl5cXlEolAgIC8Prrr6OwsBA3btyATCbDp59+arDf0aNHIZPJsGXLlkrfv/r4WX3xxRe4c+cOVqxYUW5wc3d3x7x58x76PA+Tl5eH3bt3Y8SIERg+fDjy8vLw008/VXn/xx9/HAD0PhMVcXJygq2t7UO3u3jxIi5evIgJEybo/dE5adIkCIKAnTt3Vrk+IqljzyyRBIWFheGbb77B9u3bMWXKFF17Wloa9u3bh5EjR8LKygoXLlzAjz/+iGHDhiEgIABJSUn44osv0KNHD1y8eBFeXl5GHffVV1/F999/j5deegndunXDgQMH8Mwzzxhsd+rUKRw9ehQjRoxAkyZNcPPmTaxbtw49e/bExYsXoVKp8MQTT2DatGlYtWoV5s6di5YtWwKA7vZBeXl56NmzJ65du4YpU6YgICAAO3bswNixY5Geno7p06frbb9582ZkZWXhP//5D2QyGT766CM8//zzuHHjBszNzR/6WsPDw9GrVy94eHhgxIgRmD17Nn7++WddAAe04yifffZZREREYMSIEZg+fTqysrKwf/9+nD9/Hs2aNQMAvPLKK9i0aRP69++PV199FcXFxfj7779x/PhxdOrUqcrvf1nDhg1DYGAgli5dCkEQAAD79+/HjRs3MG7cOHh4eODChQv48ssvceHCBRw/flz3x0l8fDy6dOmC9PR0TJgwAUFBQbhz5w527tyJ3NxcNG3aFN27d0d4eDjeeOMNg/fF1tYWzz33XIW11dfPas+ePbCyssLQoUOr9R6WKioqQmpqql6bSqWCSqXSHSc7OxsjRoyAh4cHevbsifDwcLz00ktVev7SP+IcHR1rVGdZ//77LwAYfH68vLzQpEkT3XqiRkEgIskpLi4WPD09ha5du+q1r1+/XgAg7Nu3TxAEQcjPzxfUarXeNjExMYJSqRQWL16s1wZA2Lhxo65t4cKFQtn/IqKiogQAwqRJk/Se76WXXhIACAsXLtS15ebmGtR87NgxAYDw7bff6tp27NghABD+/PNPg+179Ogh9OjRQ/d45cqVAgDh+++/17UVFhYKXbt2FWxsbITMzEy91+Ls7CykpaXptv3pp58EAMLPP/9scKwHJSUlCWZmZsJXX32la+vWrZvw3HPP6W339ddfCwCEFStWGDyHRqMRBEEQDhw4IAAQpk2bVuE25b3/pR58b0t/LiNHjjTYtrz3fcuWLQIA4dChQ7q20aNHC3K5XDh16lSFNX3xxRcCAOHSpUu6dYWFhYKLi4swZswYg/3Kqq+flaOjoxASElLpNmX16NFDaN26tV6bn5+fAMBgKfueP/vss0L37t11j7/88kvBzMxMSE5O1nuu0p9NdHS0kJKSIty8eVP4+uuvBSsrK8HV1VXIycmpcq2CIAgff/yxAECIiYmpcF1cXJzBus6dOwuPPvqoUccikjIOMyCSIIVCgREjRuDYsWN6X91v3rwZ7u7ueOqppwAASqUScrn2n7larcbdu3dhY2ODFi1aIDIy0qhj/vrrrwCAadOm6bXPmDHDYFsrKyvd/aKiIty9exfNmzeHg4OD0ccte3wPDw+MHDlS12Zubo5p06YhOzsbBw8e1Nv+xRdf1OsJK/2q98aNGw891tatWyGXy/HCCy/o2kaOHInffvsN9+7d07X98MMPcHFxwdSpUw2eo7QX9IcffoBMJsPChQsr3KY6Jk6caNBW9n3Pz89HamoqHn30UQDQve8ajQY//vgjBg4cWG6vcGlNw4cPh6WlJcLDw3Xr9u3bh9TU1IeOL62vn1VmZmaVvpJ/mNDQUOzfv19vKR2PfvfuXd23HaVeeOEFyGQybN++vdzna9GiBVxdXeHv74/x48ejefPm+O2333Q9vbUhLy8PgPbf+IMsLS1164kaA4ZZIokqPcFr8+bNAIDbt2/j77//xogRI6BQKABog8unn36KwMBAKJVKuLi4wNXVFWfPnkVGRoZRx4uNjYVcLtd9dV6qRYsWBtvm5eVhwYIF8PHx0Ttuenq60ccte/zAwEBdOC9VOiwhNjZWr93X11fvcWlYKhtGK/L999+jS5cuuHv3Lq5du4Zr166hffv2KCwsxI4dO3TbXb9+HS1atKj0RLnr16/Dy8sLTk5ODz2uMQICAgza0tLSMH36dLi7u8PKygqurq667Urf95SUFGRmZhpMUfUgBwcHDBw4UPf5ArRDDLy9vfHkk09Wum99/azs7OwqnaKuqlxcXNC7d2+9pWnTpgCAbdu2oaioCO3bt9d9FtLS0hAaGqoX9Mv64YcfsH//fmzevBmPPvookpOT9f7QyMvLQ2Jiot5irNLnKygoMFiXn5+vdzyiho5jZokkqmPHjggKCsKWLVswd+5cbNmyBYIg6M1isHTpUsyfPx/jx4/He++9BycnJ8jlcsyYMaNO502dOnUqNm7ciBkzZqBr166wt7eHTCbDiBEj6m2+1tJA/yChZHxpRa5evao7+SgwMNBgfXh4OCZMmFDzAsuoqIdWrVZXuE95YWX48OE4evQo3n77bbRr1w42NjbQaDTo169ftd730aNHY8eOHTh69CiCg4OxZ88eTJo0ySCk1lR1f1ZBQUGIiopCYWFhnc1+URpYu3fvXu76Gzdu6IJvqSeeeEI3m8HAgQMRHByMsLAwnD59GnK5HNu2bcO4ceP09nnYa32Qp6cnACAhIQE+Pj566xISEh46awJRQ8IwSyRhYWFhmD9/Ps6ePYvNmzcjMDAQnTt31q3fuXMnevXqhQ0bNujtl56ervtlW1V+fn7QaDS63shS0dHRBtvu3LkTY8aMwfLly3Vt+fn5BhPHG/M1u5+fH86ePQuNRqMXpi5fvqxbXxvCw8Nhbm6O7777ziBkHT58GKtWrUJcXBx8fX3RrFkznDhxAkVFRRWeqNSsWTPs27cPaWlpFfbOlvZEPvj+PNiDWZl79+4hIiICixYtwoIFC3TtV69e1dvO1dUVdnZ2OH/+/EOfs1+/fnB1dUV4eDhCQ0ORm5uLUaNGPXS/+vpZDRw4EMeOHcMPP/ygNwygtsTExODo0aOYMmUKevToobdOo9Fg1KhR2Lx5c6UzJtjY2GDhwoUYN24ctm/fjhEjRqBv377Yv39/jWpr164dAO18umWDa3x8PG7fvl3rf3ARmTIOMyCSsNJe2AULFiAqKspgblmFQmHQ47Njxw7cuXPH6GOVThK/atUqvfaVK1cabFvecVevXm3Q01g6T2dVro40YMAAJCYmYtu2bbq24uJirF69GjY2NgZho7rCw8Px+OOP48UXX8TQoUP1lrfffhsAdNNSvfDCC0hNTcWaNWsMnqf09b/wwgsQBAGLFi2qcBs7Ozu4uLjg0KFDeus///zzKtddGrwffN8f/PnI5XIMHjwYP//8s25qsPJqArRzDY8cORLbt2/Hpk2bEBwcjLZt2z60lvr6WU2cOBGenp548803ceXKFYP1ycnJeP/996v9/KW9sv/9738NPgvDhw9Hjx49KhxqUFZYWBiaNGmCDz/8EIC2V/XBYQ3Gat26NYKCgvDll1/q/btat24dZDJZjWd4IJIS9swSSVhAQAC6deumm/PywTD77LPPYvHixRg3bhy6deuGc+fOITw83OBr0apo164dRo4cic8//xwZGRno1q0bIiIicO3aNYNtn332WXz33Xewt7dHq1atcOzYMfzxxx8GVyRr164dFAoFPvzwQ2RkZECpVOLJJ5+Em5ubwXNOmDABX3zxBcaOHYvTp0/D398fO3fuxJEjR7By5cpaORHoxIkTuumkyuPt7Y0OHTogPDwcs2bNwujRo/Htt99i5syZOHnyJB5//HHk5OTgjz/+wKRJk/Dcc8+hV69eGDVqFFatWoWrV6/qvvL/+++/0atXL92xXn31VXzwwQd49dVX0alTJxw6dKjcgFYROzs7PPHEE/joo49QVFQEb29v/P7774iJiTHYdunSpfj999/Ro0cPTJgwAS1btkRCQgJ27NiBw4cPw8HBQbft6NGjsWrVKvz555+6MPYw9fGzArQ92rt378aAAQPQrl07vSuARUZGYsuWLejatWu1nz88PBzt2rUz+Bq/1KBBgzB16lRERkaiQ4cOFT6Pubk5pk+fjrfffht79+5Fv379Ktw2IyMDq1evBgAcOXIEALBmzRo4ODjAwcFB77P58ccfY9CgQXj66acxYsQInD9/HmvWrMGrr75a4RR3RA2SSLMoEFEtWbt2rQBA6NKli8G6/Px84c033xQ8PT0FKysroXv37sKxY8cMpr2qytRcgiAIeXl5wrRp0wRnZ2fB2tpaGDhwoHDr1i2DqYzu3bsnjBs3TnBxcRFsbGyEvn37CpcvXxb8/PwMpnX66quvhKZNmwoKhUJvmq4HaxQE7ZRZpc9rYWEhBAcHG0xnVfpaPv74Y4P348E6HzR16lQBgHD9+vUKt3n33XcFAMKZM2cEQdBOh/XOO+8IAQEBgrm5ueDh4SEMHTpU7zmKi4uFjz/+WAgKChIsLCwEV1dXoX///sLp06d12+Tm5gqvvPKKYG9vL9ja2grDhw8XkpOTK5yaKyUlxaC227dvC0OGDBEcHBwEe3t7YdiwYUJ8fHy5rzs2NlYYPXq04OrqKiiVSqFp06bC5MmThYKCAoPnbd26tSCXy4Xbt29X+L48qK5/VmXFx8cLb7zxhvDII48IlpaWgkqlEjp27CgsWbJEyMjI0G1X0dRczzzzjMFznj59WgAgzJ8/v8Lj3rx5UwAgvPHGG4IgVP6zycjIEOzt7Q0+0w8qfU/KW/z8/Ay23717t9CuXTtBqVQKTZo0EebNmycUFhZWegyihkYmCEaOOiciokalffv2cHJyQkREhNilEBEZ4JhZIiKq0D///IOoqCjdvKtERKaGPbNERGTg/PnzOH36NJYvX47U1FTcuHEDlpaWYpdFRGSAPbNERGRg586dGDduHIqKirBlyxYGWSIyWeyZJSIiIiLJYs8sEREREUkWwywRERERSVaju2iCRqNBfHw8bG1tjbqUJhERERHVD0EQkJWVBS8vL73LYle0sajWrFkj+Pn5CUqlUujSpYtw4sSJSrf/9NNPdRNjN2nSRJgxY4aQl5dX5eOVTvDOhQsXLly4cOHCxbSXW7duPTTbidozu23bNsycORPr169HaGgoVq5cib59+yI6Orrcy1lu3rwZs2fPxtdff41u3brhypUrGDt2LGQyGVasWFGlY5ZeRvHWrVuws7Or1ddDRERERDWXmZkJHx+fKl3+WtTZDEJDQ9G5c2esWbMGgHYIgI+PD6ZOnYrZs2cbbD9lyhRcunRJ7yo0b775Jk6cOIHDhw9X6ZiZmZmwt7dHRkYGwywRERGRCTImr4l2AlhhYSFOnz6N3r173y9GLkfv3r1x7Nixcvfp1q0bTp8+jZMnTwIAbty4gV9//RUDBgyo8DgFBQXIzMzUW4iIiIioYRBtmEFqairUajXc3d312t3d3XH58uVy93nppZeQmpqKxx57DIIgoLi4GBMnTsTcuXMrPM6yZcuwaNGiWq2diIiIiEyDpKbm+uuvv7B06VJ8/vnniIyMxK5du/DLL7/gvffeq3CfOXPmICMjQ7fcunWrHismIiIiorokWs+si4sLFAoFkpKS9NqTkpLg4eFR7j7z58/HqFGj8OqrrwIAgoODkZOTgwkTJuCdd94pd+oGpVIJpVJZ+y+AiIiIiEQnWs+shYUFOnbsqHcyl0ajQUREBLp27VruPrm5uQaBVaFQAABEPI+NiIiIiEQi6tRcM2fOxJgxY9CpUyd06dIFK1euRE5ODsaNGwcAGD16NLy9vbFs2TIAwMCBA7FixQq0b98eoaGhuHbtGubPn4+BAwfqQi0RERERNR6ihtkXX3wRKSkpWLBgARITE9GuXTvs3btXd1JYXFycXk/svHnzIJPJMG/ePNy5cweurq4YOHAglixZItZLICIiIiIRiTrPrBg4zywRERGRaZPEPLNERERERDXFMEtEREREksUwS0RERESSxTBLRERERJLFMEtEREREkiXq1FxERER1rigfyEnRLrl379/PSQFyUu/fChpAYVGymD9w37yC9oraanhfbsTc6RoNoCkC1EUlt8VlHheXaX/wcXHt7qdRa+uWKcrcyh94rABk8nK2q6328o5Xpl1Qa+vUFJdZHva4KtvUxj5qQG4GmKsAc6uSRVXBbWXrLPXbFOZ192/LRDDMEhGRtGjUQG5aBaG0nPuFWWJXbDyZ3DDkQlZ+uBQ0YldLpuyhAdnINs92gIVK7Felh2GWiIjEJQhAQeYDIbS8gJp6v3cVRk6RLjcHrF0Ba5eS29L7JY9VLtpf+poiQF2oDYrqwhreN2JbTfED74kGKM7XLtUhN9O+ZoW59r7CvORxBe1ys4rX6bVX9hwK7R8aguZ+D6ig1vYc6z0u2UbvcXXay3veSo4naO731srNyiy1/bi0TVGFbco8lsm1tRblAkV5ZW7zymkrb90D60v/jWiKtf++CjKr91l60JTTgEvz2nmuWsIwS0QkNXnpQEo0kHIJSL6svc1MKPO1a0Vfy8rE+Wq39CvzvHsV96KqC418E2SAyumBYFpyX+Vcpr1knaW99vWbKkF4eOAVNFUPmKb8WqnuCYL2M2N0IK7COgtrsV+dAYZZIiJTlZ+hDa3Jl4CUy/dvsxLErqxuWNiW03Na3q0rYOWkDXANhUwGmFloF6KakskAM6V2sXIUu5o614D+JyAikqj8TMOe1uTLQFZ8xfvYeQOuQdrFLQhw8NP+Aqvzr3ar+ZWvIJT0pLpov9IvL7CaW9Xfe05EDQbDLBFRfSnIKr+nNfNOxfvYegGuLQC3liXBtaX2saV9/dVNRGTCGGaJiGpbQXaZntaSwJoSDWTcqngfGw9tD6try/u3ri0AK4d6K5uISIoYZolIfOqS6YXk5tqThqSiIBtIjb4/NCCl5H5GXMX72LiX6WEtM0ygEYxrIyKqCwyzRFQ/NGptz+Tda8Dd6yW3JUv6LeimkZGbVW1i+dIzt+tq0voHnzsnpaSH9fL98JpeSWi1dtPvYS0Nryqnenm7iYgaC4ZZIqo9ggBkJ+sH1dLgei+matMvlV4Np6juy60V1q76PayuLbXBlaGViKheMMwSkfHy0oG06w/0sJY8ruxqSwol4NQUcG4GODe/f+vUTHsJRr3J5mtj0vpqTmBv0FYAKG3LjGctHSbQErB2rre3nYiIDDHMElH5ivKAtJj7YbVseM1JqXg/mRxw8L0fUsuGVvsmxl1znoiI6CEYZokaM3Wx9mSluzcMhwZklBnHWh4bd/2gWro4+msn6iYiIqoHDLNEjUFWEnD3quE41rQY7bXoK6K0fyCslg4LaApY2tVf/URERBVgmCVqqIoLgIt7gH82AHHHKt5OoSwJqQ/0sDo1016Vidd4JyIiE8YwS9TQ3IsFTm8CIr8FclO1bTK59nKnej2sJeHVrom05nYlIiIqg2GWqCHQaIDrEcCp/wOu7INurKutJ9BxHNBhNGDnKWqJREREdYFhlkjKcu4C/34H/PM1kB57v71pT6DTK0CL/tpJ/4mIiBoohlkiqREE4PYpbS/shR+1c6ACgKU90C4M6DQecAkUtUQiIqL6wjBLJBUF2cC5HcCpDUDSufvtnu2Azq8CbV4ALFSilUdERCQGhlkiU5cSrQ2wZ7YABZnaNjNLbXjt/Arg3VHc+oiIiETEMEtkiooLgcv/046Fvfn3/XanptqxsO1eAlRO4tVHRERkIhhmiUxJxp2SabW+AbKTtG0yOdBigLYXNqAnp9EiIiIqg2GWSGwaDRDzl3YoQfSvgKDRttu4Ax3GAB3HAPZNRC2RiIjIVDHMEoklNw2I2qwdSpB2/X67/+PaGQmCngXMLMSrj4iISAIYZonq253T2l7Y8z8AxfnaNqUdEDJCOx7WLUjc+oiIiCSEYZaoPhTmasPrPxuA+H/vt7sHa8fCBg8DlDbi1UdERCRRDLNEdSn1mnYYQdT3QH6Gtk1hAbQeop0btklnQCYTt0YiIiIJY5glqm3qYu2JXP9sAG78db/dwU87Frb9y4C1i2jlERERNSQMs0S1JTMBiPxWO7VWVnxJowx4pK+2F7bZU5xWi4iIqJYxzBLVhLpYO61W5LfA5V8ATbG2XeUCdBgNdBwLOPqJWSEREVGDxjBLZCxB0M5IcG4HcH4XkJN8f51vV+2MBK0GAWZK8WokIiJqJBhmiaoq9Rpwbrs2xKbduN+ucgZaP6/thfVoI1p5REREjRHDLFFlshK1U2qd3Q4kRN1vN1cBQc8AwcOBZr0AhbloJRIRETVmDLNED8rPAC79rA2wN/++f3lZmQJo/pQ2wLboz3lhiYiITADDLBEAFBcAV3/XBtgr+wB1wf11PqHaixq0HsIptYiIiEwMwyw1XhoNEHtYG2Av7gEKMu6vc2kBtB2mDbGO/qKVSERERJVjmKXGRRCAxLPaAHt+V5n5YAHYegHBL2iHEXgE88pcREREEsAwS41DWgxwfidwdgeQGn2/3dIeaPWcNsD6dQPkCvFqJCIiIqMxzFLDlZMKXNit7YW9ffJ+u0IJtOinDbCBfTgfLBERkYQxzFLDUpANRP+qDbDXDwCCWtsukwMBT2gDbMtntT2yREREJHkMsyR96iJtcD27XRtki3Lvr/Nqrw2wbZ4HbD3Eq5GIiIjqBMMsSZMgALdOaAPshd1AXtr9dY4BQNvh2pkIXALFq5GIiIjqHMMsSUvypZKZCHYC6XH3261dgTYlMxF4d+BMBERERI0EwyyZvsx4bYA9txNIOne/3cIGaDlQ2wMb0ANQ8ONMRETU2PC3P5muhLPA0dXAhV2ApljbJjfXzkAQPAx4pB9goRK3RiIiIhIVwyyZFkHQnsx1dBVw46/77b5dgbYvaueEVTmJVh4RERGZFoZZMg3qIuD8D9qe2KTz2jaZAmg9GOg2VTsrAREREdEDGGZJXPmZwOlNwIn1QOYdbZu5NdBhNPDo64Cjn6jlERERkWljmCVxZNzRBtjTm4CCTG2bjTsQ+h+g03jAylHU8oiIiEgaGGapfiWeB46tAc7tuH9Sl0sL7VCCtsN5aVkiIiIyCsMs1T1B0J7MdXQ1cD3ifrvfY0D3aUDzPoBcLlp5REREJF0Ms1R31EXaq3MdXQUklswPK5NrZyToNhXw7ihufURERCR5DLNU+wqygMhvgePrgIxb2jZzFdB+lPakLqcAcesjIiKiBoNhlmpPZoL2pK5/NgIFGdo2a1egy3+Azq9wflgiIiKqdQyzVHPJl7TjYc9uBzRF2jbnQKDbFKDtCMDcUtz6iIiIqMFimKXqEQTg5t/AkVXAtf332327At2maS81y5O6iIiIqI4xzJJx1MXAxR+1PbEJUSWNMqDlQG2I9eksYnFERETU2DDMUtUUZAP/fgcc+xzIiNO2mVkB7cOARycBzs3ErY+IiIgaJYZZqlxWEnDyC+DUBiA/Xdumci45qetVwNpZ1PKIiIiocWOYpfKlRJec1LUNUBdq25yaAl2nAO1eAsytxK2PiIiICAyzVJYgALFHtRc5uLL3fnuTLtordbUYAMgV4tVHRERE9ACTON187dq18Pf3h6WlJUJDQ3Hy5MkKt+3ZsydkMpnB8swzz9RjxQ2MRq29UtdXTwKbBpQEWRkQ9Cww/nfg1f3aE7wYZImIiMjEiN4zu23bNsycORPr169HaGgoVq5cib59+yI6Ohpubm4G2+/atQuFhYW6x3fv3kVISAiGDRtWn2U3HOm3gO+GAHevah8rlNphBF2nAC7Nxa2NiIiI6CFkgiAIYhYQGhqKzp07Y82aNQAAjUYDHx8fTJ06FbNnz37o/itXrsSCBQuQkJAAa2vrh26fmZkJe3t7ZGRkwM7Orsb1S9720cDFnwArJ6DLa0Dn1wAbV7GrIiIiokbMmLwmas9sYWEhTp8+jTlz5uja5HI5evfujWPHjlXpOTZs2IARI0ZUGGQLCgpQUFCge5yZmVmzohuS2KPaICuTA2P/B7i3FrsiIiIiIqOIOmY2NTUVarUa7u7ueu3u7u5ITEx86P4nT57E+fPn8eqrr1a4zbJly2Bvb69bfHx8alx3g6DRAHtL/ojoMIZBloiIiCTJJE4Aq64NGzYgODgYXbp0qXCbOXPmICMjQ7fcunWrHis0YWe3aa/gpbQDer0jdjVERERE1SLqMAMXFxcoFAokJSXptSclJcHDw6PSfXNycrB161YsXry40u2USiWUSmWNa21QCnOAiEXa+4+/yTGyREREJFmi9sxaWFigY8eOiIiI0LVpNBpERESga9eule67Y8cOFBQU4OWXX67rMhueI58BWQmAgx/w6OtiV0NERERUbaJPzTVz5kyMGTMGnTp1QpcuXbBy5Urk5ORg3LhxAIDRo0fD29sby5Yt09tvw4YNGDx4MJydeTlVo2TcAY6s0t7vsxgwY681ERERSZfoYfbFF19ESkoKFixYgMTERLRr1w579+7VnRQWFxcHuVy/Azk6OhqHDx/G77//LkbJ0haxCCjOA3y7Aa2eE7saIiIiohoRfZ7Z+tao55m9fRr4vycByIAJfwJe7cWuiIiIiMiAMXlN0rMZkBEEAdg3V3s/ZCSDLBERETUIDLONxYXdwK3jgLkKeGqB2NUQERER1QqG2cagKB/Yv1B7v/sMwM5T1HKIiIiIagvDbGNwfC2QEQfYeQPdpopdDREREVGtYZht6LKSgL9XaO8/tRCwUIlbDxEREVEtYpht6P58HyjMBrw6AMHDxK6GiIiIqFYxzDZkieeAyO+09/t9AMj54yYiIqKGhemmoRIEYO8cAALQ+nnAN1TsioiIiIhqHcNsQxX9K3Dzb0ChBPosErsaIiIiojrBMNsQFRcCv8/T3u86GXDwFbceIiIiojrCMNsQnfoKSLsBWLsBj88UuxoiIiKiOsMw29DkpgEHP9Tef3IeoLQVtx4iIiKiOsQw29D8tQzIzwDcg4H2L4tdDREREVGdYphtSFKigVMbtPf7LQXkCnHrISIiIqpjDLMNyb53AEENtHgGCHhC7GqIiIiI6hzDbENx7Q/g2n5Abg48/Z7Y1RARERHVC4bZhkBdrO2VBYAuEwDnZuLWQ0RERFRPGGYbgshNQMplwMoJ6PG22NUQERER1RuGWanLSwf+XKq932suYOUoajlERERE9YlhVur+/gTIvQu4tAA6jhO7GiIiIqJ6xTArZXevA8fXa+/3XQIozMSth4iIiKieMcxK2f4FgKYIaPYUENhH7GqIiIiI6h3DrFTF/A1c/h8gU2h7ZYmIiIgaIYZZKdKogX1ztfc7jgXcWopaDhEREZFYGGal6MwWIPEsoLTXzmBARERE1EgxzEpNQTYQsVh7v8fbgLWLuPUQERERiYhhVmqOrASykwDHAO3VvoiIiIgaMYZZKUm/BRxdrb3/9HuAmVLceoiIiIhExjArJX+8CxTnA36PAUHPil0NERERkegYZqXi1ing/E4AMqDfUkAmE7siIiIiItExzEqBIAD75mjvtwsDPEPErYeIiIjIRDDMSsH5H4DbpwBza+Cp+WJXQ0RERGQyGGZNXVEesH+h9v7jbwC2HuLWQ0RERGRCGGZN3dE1QOZtwN4H6DpF7GqIiIiITArDrCnLTAAOf6q93/tdwNxK1HKIiIiITA3DrCk78D5QlAM06Qy0eUHsaoiIiIhMDsOsqYqPAqLCtff7LuNUXERERETlYJg1RYIA7HsHgAC0GQr4dBa7IiIiIiKTxDBrii7/D4g9DJhZasfKEhEREVG5GGZNTXEB8Ps87f1uUwEHH3HrISIiIjJhDLOm5sQXwL2bgI0H0H2G2NUQERERmTSGWVOSkwoc+lh7/6n5gNJG3HqIiIiITBzDrCn5cylQkAl4tAVCXhK7GiIiIiKTxzBrKpIvAac3au/3WwbI+aMhIiIiehgmJlMgCMC+uYCgAVoOBPwfE7siIiIiIklgmDUFV/cD1w8ACgugz2KxqyEiIiKSDIZZsamLgN/f0d4P/Q/g1FTceoiIiIgkhGFWbP9sBFKvACpn4Im3xa6GiIiISFIYZsWUdw/4a6n2fq+5gKW9uPUQERERSQzDrJgOfqwNtK4tgQ5jxa6GiIiISHIYZsWSeg04+YX2ft/3AYWZuPUQERERSRDDrFj2zwc0xUDg00Dz3mJXQ0RERCRJDLNiuHEQiP4VkCmAp98XuxoiIiIiyWKYrW8atfYCCQDQ+RXAtYW49RARERFJGMNsffv3eyDpvHbmgp5zxK6GiIiISNIYZutTQRZwoGRYQY9ZgMpJ3HqIiIiIJI5htj79vQLISQacmgGdXxO7GiIiIiLJY5itL/digWNrtfeffh8wsxC3HiIiIqIGgGG2vvyxEFAXAAFPAC36i10NERERUYPAMFsf4o4DF3YDkAF9lwIymdgVERERETUIDLN1TaMB9pbMWtBhFOARLG49RERERA0Iw2xdO7cDiI8ELGyAXvPEroaIiIioQWGYrWvnd2pvH58J2LqLWwsRERFRA2MmdgEN3sitwNltQOvnxa6EiIiIqMFhmK1rcgXQ7iWxqyAiIiJqkDjMgIiIiIgki2GWiIiIiCRL9DC7du1a+Pv7w9LSEqGhoTh58mSl26enp2Py5Mnw9PSEUqnEI488gl9//bWeqiUiIiIiUyLqmNlt27Zh5syZWL9+PUJDQ7Fy5Ur07dsX0dHRcHNzM9i+sLAQffr0gZubG3bu3Alvb2/ExsbCwcGh/osnIiIiItHJBEEQxDp4aGgoOnfujDVr1gAANBoNfHx8MHXqVMyePdtg+/Xr1+Pjjz/G5cuXYW5uXq1jZmZmwt7eHhkZGbCzs6tR/URERERU+4zJa6INMygsLMTp06fRu3fv+8XI5ejduzeOHTtW7j579uxB165dMXnyZLi7u6NNmzZYunQp1Gp1hccpKChAZmam3kJEREREDYNoYTY1NRVqtRru7voXEnB3d0diYmK5+9y4cQM7d+6EWq3Gr7/+ivnz52P58uV4//33KzzOsmXLYG9vr1t8fHxq9XUQERERkXhEPwHMGBqNBm5ubvjyyy/RsWNHvPjii3jnnXewfv36CveZM2cOMjIydMutW7fqsWIiIiIiqkuinQDm4uIChUKBpKQkvfakpCR4eHiUu4+npyfMzc2hUCh0bS1btkRiYiIKCwthYWFhsI9SqYRSqazd4omIiIjIJBjdM+vv74/FixcjLi6uRge2sLBAx44dERERoWvTaDSIiIhA165dy92ne/fuuHbtGjQaja7typUr8PT0LDfIEhEREVHDZnSYnTFjBnbt2oWmTZuiT58+2Lp1KwoKCqp18JkzZ+Krr77CN998g0uXLuH1119HTk4Oxo0bBwAYPXo05syZo9v+9ddfR1paGqZPn44rV67gl19+wdKlSzF58uRqHZ+IiIiIpK1aYTYqKgonT55Ey5YtMXXqVHh6emLKlCmIjIw06rlefPFFfPLJJ1iwYAHatWuHqKgo7N27V3dSWFxcHBISEnTb+/j4YN++fTh16hTatm2LadOmYfr06eVO40VEREREDV+N55ktKirC559/jlmzZqGoqAjBwcGYNm0axo0bB5lMVlt11hrOM0tERERk2ozJa9U+AayoqAi7d+/Gxo0bsX//fjz66KN45ZVXcPv2bcydOxd//PEHNm/eXN2nJyIiIiJ6KKPDbGRkJDZu3IgtW7ZALpdj9OjR+PTTTxEUFKTbZsiQIejcuXOtFkpERERE9CCjw2znzp3Rp08frFu3DoMHDy73srIBAQEYMWJErRRIRERERFQRo8PsjRs34OfnV+k21tbW2LhxY7WLIiIiIiKqCqNnM0hOTsaJEycM2k+cOIF//vmnVooiIiIiIqoKo8Ps5MmTy70k7J07dzjfKxERERHVK6PD7MWLF9GhQweD9vbt2+PixYu1UhQRERERUVUYHWaVSiWSkpIM2hMSEmBmVu2ZvoiIiIiIjGZ0mH366acxZ84cZGRk6NrS09Mxd+5c9OnTp1aLIyIiIiKqjNFdqZ988gmeeOIJ+Pn5oX379gCAqKgouLu747vvvqv1AomIiIiIKmJ0mPX29sbZs2cRHh6OM2fOwMrKCuPGjcPIkSPLnXOWiIiIiKiuVGuQq7W1NSZMmFDbtRARERERGaXaZ2xdvHgRcXFxKCws1GsfNGhQjYsiIiIiIqqKal0BbMiQITh37hxkMhkEQQAAyGQyAIBara7dComIiIiIKmD0bAbTp09HQEAAkpOToVKpcOHCBRw6dAidOnXCX3/9VQclEhERERGVz+ie2WPHjuHAgQNwcXGBXC6HXC7HY489hmXLlmHatGn4999/66JOIiIiIiIDRvfMqtVq2NraAgBcXFwQHx8PAPDz80N0dHTtVkdEREREVAmje2bbtGmDM2fOICAgAKGhofjoo49gYWGBL7/8Ek2bNq2LGomIiIiIymV0mJ03bx5ycnIAAIsXL8azzz6Lxx9/HM7Ozti2bVutF0hEREREVBGZUDodQQ2kpaXB0dFRN6OBKcvMzIS9vT0yMjJgZ2cndjlERERE9ABj8ppRY2aLiopgZmaG8+fP67U7OTlJIsgSERERUcNiVJg1NzeHr68v55IlIiIiIpNg9GwG77zzDubOnYu0tLS6qIeIiIiIqMqMPgFszZo1uHbtGry8vODn5wdra2u99ZGRkbVWHBERERFRZYwOs4MHD66DMoiIiIiIjFcrsxlICWczICIiIjJtdTabARERERGRKTF6mIFcLq90Gi7OdEBERERE9cXoMLt79269x0VFRfj333/xzTffYNGiRbVWGBERERHRw9TamNnNmzdj27Zt+Omnn2rj6eoMx8wSERERmTZRxsw++uijiIiIqK2nIyIiIiJ6qFoJs3l5eVi1ahW8vb1r4+mIiIiIiKrE6DGzjo6OeieACYKArKwsqFQqfP/997VaHBERERFRZYwOs59++qlemJXL5XB1dUVoaCgcHR1rtTgiIiIiosoYHWbHjh1bB2UQERERERnP6DGzGzduxI4dOwzad+zYgW+++aZWiiIiIiIiqgqjw+yyZcvg4uJi0O7m5oalS5fWSlFERERERFVhdJiNi4tDQECAQbufnx/i4uJqpSgiIiIioqowOsy6ubnh7NmzBu1nzpyBs7NzrRRFRERERFQVRofZkSNHYtq0afjzzz+hVquhVqtx4MABTJ8+HSNGjKiLGomIiIiIymX0bAbvvfcebt68iaeeegpmZtrdNRoNRo8ezTGzRERERFSvZIIgCNXZ8erVq4iKioKVlRWCg4Ph5+dX27XVCWOu9UtERERE9c+YvGZ0z2ypwMBABAYGVnd3IiIiIqIaM3rM7AsvvIAPP/zQoP2jjz7CsGHDaqUoIiIiIqKqMDrMHjp0CAMGDDBo79+/Pw4dOlQrRRERERERVYXRYTY7OxsWFhYG7ebm5sjMzKyVooiIiIiIqsLoMBscHIxt27YZtG/duhWtWrWqlaKIiIiIiKrC6BPA5s+fj+effx7Xr1/Hk08+CQCIiIjA5s2bsXPnzlovkIiIiIioIkaH2YEDB+LHH3/E0qVLsXPnTlhZWSEkJAQHDhyAk5NTXdRIRERERFSuas8zWyozMxNbtmzBhg0bcPr0aajV6tqqrU5wnlkiIiIi02ZMXjN6zGypQ4cOYcyYMfDy8sLy5cvx5JNP4vjx49V9OiIiIiIioxk1zCAxMRGbNm3Chg0bkJmZieHDh6OgoAA//vgjT/4iIiIionpX5Z7ZgQMHokWLFjh79ixWrlyJ+Ph4rF69ui5rIyIiIiKqVJV7Zn/77TdMmzYNr7/+Oi9jS0REREQmoco9s4cPH0ZWVhY6duyI0NBQrFmzBqmpqXVZGxERERFRpaocZh999FF89dVXSEhIwH/+8x9s3boVXl5e0Gg02L9/P7KysuqyTiIiIiIiAzWamis6OhobNmzAd999h/T0dPTp0wd79uypzfpqHafmIiIiIjJt9TI1FwC0aNECH330EW7fvo0tW7bU5KmIiIiIiIxW44smSA17ZomIiIhMW731zBIRERERiYlhloiIiIgki2GWiIiIiCSLYZaIiIiIJIthloiIiIgki2GWiIiIiCSLYZaIiIiIJIthloiIiIgkyyTC7Nq1a+Hv7w9LS0uEhobi5MmTFW67adMmyGQyvcXS0rIeqyUiIiIiUyF6mN22bRtmzpyJhQsXIjIyEiEhIejbty+Sk5Mr3MfOzg4JCQm6JTY2th4rJiIiIiJTIXqYXbFiBV577TWMGzcOrVq1wvr166FSqfD1119XuI9MJoOHh4ducXd3r8eKiYiIiMhUiBpmCwsLcfr0afTu3VvXJpfL0bt3bxw7dqzC/bKzs+Hn5wcfHx8899xzuHDhQoXbFhQUIDMzU28hIiIiooZB1DCbmpoKtVpt0LPq7u6OxMTEcvdp0aIFvv76a/z000/4/vvvodFo0K1bN9y+fbvc7ZctWwZ7e3vd4uPjU+uvg4iIiIjEIfowA2N17doVo0ePRrt27dCjRw/s2rULrq6u+OKLL8rdfs6cOcjIyNAtt27dqueKiYiIiKiumIl5cBcXFygUCiQlJem1JyUlwcPDo0rPYW5ujvbt2+PatWvlrlcqlVAqlTWulYiIiIhMj6g9sxYWFujYsSMiIiJ0bRqNBhEREejatWuVnkOtVuPcuXPw9PSsqzKJiIiIyESJ2jMLADNnzsSYMWPQqVMndOnSBStXrkROTg7GjRsHABg9ejS8vb2xbNkyAMDixYvx6KOPonnz5khPT8fHH3+M2NhYvPrqq2K+DCIiIiISgehh9sUXX0RKSgoWLFiAxMREtGvXDnv37tWdFBYXFwe5/H4H8r179/Daa68hMTERjo6O6NixI44ePYpWrVqJ9RKIiIiISCQyQRAEsYuoT5mZmbC3t0dGRgbs7OzELoeIiIiIHmBMXpPcbAZERERERKUYZomIiIhIshhmiYiIiEiyGGaJiIiISLIYZomIiIhIshhmiYiIiEiyGGaJiIiISLIYZomIiIhIshhmiYiIiEiyGGaJiIiISLIYZomIiIhIshhmiYiIiEiyGGaJiIiISLIYZomIiIhIshhmiYiIiEiyGGaJiIiISLIYZomIiIhIshhmiYiIiEiyGGaJiIiISLIYZomIiIhIshhmiYiIiEiyGGaJiIiISLIYZomIiIhIshhmiYiIiEiyGGaJiIiISLIYZomIiIhIshhmiYiIiEiyGGaJiIiISLIYZomIiIhIshhmiYiIiEiyGGaJiIiISLIYZomIiIhIshhmiYiIiEiyGGaJiIiISLIYZomIiIhIshhmiYiIiEiyGGaJiIiISLIYZomIiIhIshhmiYiIiEiyGGaJiIiISLIYZomIiIhIshhmiYiIiOihBEEQu4RymYldABEREVFtK1JrcC05G5cTM3EpIQsxqTlws1WiuZuNbvGws4RMJhO7VJOj1gi4lZaLq8nZuJqchWtJ2bianI0bKdk48U5v2ChNKz6aVjVERERERrqbXYDLiVm4lJCJiwna8HotOQtF6sp7Em2UZmjmao1mrjZoVibk+jmpYKZo+F9eF6k1iL2bg6slYfVasvb2eko2Cos15e5zPTkbIT4O9VvoQzDMEhERkSQUqzWISc3RBdZLCZm4lJCJ5KyCcre3VZohyNMWLT3t0NTFGslZBbiWnI1rKdmIvZuL7IJinLmdgTO3M/T2M1fI4O9srQu3zVy1t01draGykF50yi9SIyY1RxdWryVn4WpSNmJSc1CsKT/wK83kaOZqg0B3GwTqgr4t/J1V9Vz9w0nvJ0JEREQNXkZuUUlo1S6XE7NwJSkLBRX0GPo5q9DSww4tPe3QsiTANnG0qnAYQWGxtlfyWklPZGnIvZ6cg7widclX7NkG+3k7WOkNVWjuZoPmrjZwtLao1ddfHXmFalxP0Q4NKNvbGns3BxVkVqgsFCVh1RaB7trXEuhugyaOKijk0hiCIRNMdTRvHcnMzIS9vT0yMjJgZ2cndjlERESNmloj4ObdHG1gLdPbGp+RX+72KgsFgjxsS0KrdmnhYVtr4zg1GgHxGXnacJucjespObheEnTTcgor3M/J2gLNHxiu0NzNBl72tT8uNyu/qEwvazauJmXhanI27qTnoaJUZ2tphkfcbcv0stog0N0WnnaWkJtgaDUmrzHMEhERUb3IzC/C5YSskpOyMnExIQtXErOQV6Qud/smjla6wNrK0xZBHnbwdVKJFr7Scgp1Ibdsj+6d9LwK91FZKNDU1RrNXfVDrp+zNcwfMi43PbdQ20OcVHIiVslxEyoI+gDgbG1xP6yWBNZANxu42ioldbIbw2wlGGaJiIjqlkYj4Na9XF1gLe1tvX2v/NBnaS5HC4/7gbWlpx2CPG1hZ2lez5VXT25hMW6k5OgF3Wsp2bhZyZhUM7kMfs4q3ZjcZq42yC0sLhNes5GaXf5YYABwt1OWBFZbXXBt7mYDZxtlXb3MemVMXuOYWSIiCcovUuPcnQxExt5DZNw9JGbko4mjCn7OKvg7W2tvXazhJrHeGJKegmI1Lidk4dydDF1ojU7MQk5h+b2tXvaWut7W0pOz/J2tJTM+szwqCzO08bZHG297vfYitQZxabn3e3J143KzkVOo1g5hSMkBkFThc5eO0dX2smrHtjZ3s4G9lTSCfn1gmCUiMnGCIOD2vTxExt3Dv3HpiIy7h4vxmQY9Pg+ekQ1oe7z8nO6H27Jh19PeStIBgupfsVqDaynZOHsrA2dup+Ps7QxcTswsdwosCzM5WrjbomWZ3taWnrZwUIl/olR9MVfIdb2ufVvfbxcEAYmZ+Xo9uTdScrQnY5UMCwh01+5nbWJzupoiDjMgIjIx+UVqnL2dgci4e4iMvYd/b6UjpZyph1xtlejg64AOvo7wdVLhTnoeYu/m4ubdHMTezcWd9DyoKzqFGYCFQo4mTlb3e3LL3Ho7Wj10PJ+UCYKAzPxi3MspRFpuIdJzC+GgskAzV/Z4lRIEATfv5uLs7XScuZWBs7fTcSE+s9zxrY4qcwQ3cUCrksDaytMOAS7WjWKuVqobHGZARCQRZXtdS4Nreb2uZnIZWnvZob2vI9qXBNjKph0CtF9x3rmXpwu3ZW9vpeWiUK3BjZQc3EjJMdhXIZfB28HKIOT6u6jQxFEFS3NFrb8X1SUIAnIK1dpgWhJOS+/fyy1EWk6RLrTeK2m7l1tUYdB3sVFqJ9J3s0FTF+1tc1cbeDk03J5sQRCQkJGvDa63tcH13O0MZOYXG2xrozRDG287hDRxQNsmDmjbxP6hn0WiusSeWSKiepRXqMbZ2+mIjEvHv3H3EBmXXu5JHmV7XTv4OSLY275WA6RaIyA+PQ9xaWVCbqr2NjYtB/lF5c/lCQAyGeBlbwVfJxX8XVTwc7aGv7P21s9ZVeNJ5fMK1eUE0sIygbRIvz238KFXeqqIjdIMDipzOKjMcTe7sNKzxJVmcgSUhNtmpbeuNghwsZbcV8F3swtw9vb9oQJnb2eU+zlUmsnRyqs0uNqjbRMHNHWxNsmpnKhh4WwGlWCYJaL6IggCbqWVjnXVBtdLCZX3unbwc0QHXwd4O4jX06XRCEjOKigJuSUBt0zPbnaBYW9dWW62Svg564dcb0crbUg1CKdFutCanqsNq5UF6cpYmsvhpLKAo7UFnKwt4Kgqe2uubS+z3kFlDqWZ/h8I2QXFiEnJwfWU7PtLcg5i7uZUeHlPQHtSU2m4bVp6eVRXG7jbiX8CXmZ+Ec6XXOXqbEl4LW8qKYVchhbutgjxsdf1uD7ibtugh5uQ6WKYrQTDLBHVlbxCNc7cTtedpPVv3D2kZhtOsu5mqyzpcdX2vLap5V7XuiQIAu7mFCL2bg5upuZqw25aLm7e1d5Pzy2qleNYKORwtDa/H0jLBlGVebmB1cqi7t5DtUbAnXt5BiH3eko27lYykb61hUIXcpu5WqNpScj1d1EZBOnakF+kxoX4DJy5lYFzd7Q9r+UNI5HJgKYu1roe1+AmDmjtZSeZzyE1fAyzlWCYJaLaIAgC4tJydcE1Mu4eLiVkGYzDNFfI0MrLXjdkoL3Iva51LT230GB8btzdXMSn58HG0qz8cFo2tJa0WVsoJPMe3cspxI3UkitFlYTcGynZiE3LrXBcrlwG+DipdCFX26Orve9kbVGl116k1iA6MQtnSsa3nrmdgStJhp9BQHvxgfvB1R7B3vawlcgcrtQ4McxWgmGWiKojt7C4zAwD6Yi6VX6vq7tdSa9rSXCVUq8r1a7CYg3i0nJwLfn+sIUbJZdGzapkqIaDyrzckKvWCDhzOwPnSk7SupiQWe7QB1dbJUKa2CPY2wFtfezR1tu+wUykT40Hw2wlGGaJqKxitQZ3cwqRklWAlOwC7W3pUuZxXDm9bOYKGVp72euCawc/xzq5Djs1LIIgICW7QDdMQbtoQ25ll0Utj52lmW58a9smDgjxsYeHHT+DJH2cmouIGjVBEJCRV1RuKH3wcVpuIar6J33ZXtcOfg5o7cVeVzKeTCaDm60l3Gwt0bWZs966vEI1YlINQ+6N1GzIIEMbbztdeA1p4gA/ZxWDKzV6DLNEJBm5hcUVhtLSx6klt8ZM1SSXAc42SrjaKOFqW2Yp89jXSQUvB6s6fHVEgJWFAq287NDKS78nSlPyrQCnxCIyxDBLRKJLzS5AfHqeLpSmZpcfViu61ntF7K3MDUJpeY8dVRYNdjJ8ahgYYokqxjBLRPWqdO7VkzfTcDLmLk7GpOHm3dwq729pLoebreVDQ6qzjUWdTH1ERESmhWGWiOqURiPgWko2Tsak6ZbETP2rLMlkgHtpQC0vpNoq4VLSJqUpm4iIqO4xzBJRrSpWa3ApIQsnSnpdT91Mw70HJtI3V8jQtokDOvs7ITTACR38HGFvxTkviYjIeAyzRFQjBcVqnL2dgZMxaTgRk4bTN9MMxrZamsvRwdcRXQKc0CXACe19HOv0ak1ERNR4MMwSkVFyCooRGXdPF16jbqUbTNxua2mGzv5OuvDaxsseFma8vjsREdU+hlkiqlR6biFO3bynO1nrfHymwcUDXGwstMHV3wldApzRwsOWswMQEVG9MIkwu3btWnz88cdITExESEgIVq9ejS5dujx0v61bt2LkyJF47rnn8OOPP9Z9oUSNQFJmvt7JWtFJWQbbeDtYITTACZ1Lel6buljzpCwiIhKF6GF227ZtmDlzJtavX4/Q0FCsXLkSffv2RXR0NNzc3Crc7+bNm3jrrbfw+OOP12O1RA1L6TRZZU/WKm+arGau1rohA539ndDEUSVCtURERIZkglDVCznWjdDQUHTu3Blr1qwBAGg0Gvj4+GDq1KmYPXt2ufuo1Wo88cQTGD9+PP7++2+kp6dXuWfWmGv9EjU0pdNknYhJw6lKpslq6WGHLgHamQY6+TvB1VYpUsVERNQYGZPXRO2ZLSwsxOnTpzFnzhxdm1wuR+/evXHs2LEK91u8eDHc3Nzwyiuv4O+//670GAUFBSgoKNA9zszMrHnhRBIgCAKSswpwLTkblxIyK5wmy0wuQ9sm9ugS4MxpsoiISHJEDbOpqalQq9Vwd3fXa3d3d8fly5fL3efw4cPYsGEDoqKiqnSMZcuWYdGiRTUtlchkCYKA+Ix8XE3KwrXkbFxNysbV5CxcTc5GVn6xwfacJouIiBoS0cfMGiMrKwujRo3CV199BRcXlyrtM2fOHMycOVP3ODMzEz4+PnVVItWy1OwCbDgcg6TMfHg7WGkXR+2tl4MVLM0bTwhTawTcvpdbEla1gfVacjauJ2cbzOtaSi4D/Jyt0dzNBh39HNHZ3wnB3pwmi4iIGg5Rw6yLiwsUCgWSkpL02pOSkuDh4WGw/fXr13Hz5k0MHDhQ16bRaOe3NDMzQ3R0NJo1a6a3j1KphFLJ8X5Sk11QjK8O3cD//X2jwqAGAC42ypJwa1km7Kp0oVeKX5cXqTWIvZuLa8lZuuB6LTkb11OyUfDAfK6lzOQyBLhYI9DdBs3dbBHoZoPmbjYIcLFuVIGfiIgaH1HDrIWFBTp27IiIiAgMHjwYgDacRkREYMqUKQbbBwUF4dy5c3pt8+bNQ1ZWFj777DP2uDYAhcUabD4Ri9UHruFuTiEAoG0Tezzdyh0JGfm4k56HO/fycCc9D7mFaqRmFyA1uwBnbpX/fLZKM72e3NL73o5WaOJgBRcbJeQizYdaUKxGTGoOriZpw+q1kt7WmNQcFKnLPy/TwkyOZq42CHQrWdy1odXP2RrmCva2EhFR4yP6MIOZM2dizJgx6NSpE7p06YKVK1ciJycH48aNAwCMHj0a3t7eWLZsGSwtLdGmTRu9/R0cHADAoJ2kRaMR8PPZeCz//Qri0rRTQwW4WOOtp1tgQLCHwRymgiAgI68It0uC7Z0Hb9PzkJZTiKyCYlxOzMLlRMO5UgHAQiGHl4OlfuDVhV0VPOwta/yVfF6hGtdT7ofV0vAam5ZrcPGBUioLBZqX9K4GutmW3NrAx0nFixEQERGVIXqYffHFF5GSkoIFCxYgMTER7dq1w969e3UnhcXFxUEuZ49TQyUIAg5dTcWHv13GxQTtTBOutkrM6B2I4Z18KuxtlMlkcFBZwEFlgTbe9uVuk1tYjPj0PNxJzy8Jubl6oTcxMx+Fag1u3s0td25V7XEAd1tLvR5dLwdtr25pm7VS+88ou6C45ASskhOxSsLr7Xt5qGgCPFtLs5JeVltdL2tzNxt42VuJ1mNMREQkJaLPM1vfOM+s6ThzKx0f7r2Mo9fvAtAOCfhPj6YY/1gAVBZ1/3dWkVqDxDJDF+LT7/fqlobeisaoluWgMoelmcJgvtayHFXmCHS31Q0PaF4SXt1slbxyFhER0QMkM88sNU4xqTn4ZF80fjmXAED7Vf+orn6Y3Ks5nKwt6q0Oc4UcPk4q+DiVfzUrQRCQml1YJtyW9uyWBuBcZOYXIz23CIB27lY3WyUC3e8PDSgdHuBsw5MQiYiI6gLDLNWb5Mx8fBZxFVtP3YJaI0AmA4a098bMPo+Y5OVRZTIZXG2VcLVVop2PQ7nbZOUX4U56HvIK1WjqYgN7lfRmTyAiIpIyhlmqc5n5Rfjy4A1sOByDvCLtNFtPBrnhv/1aIMhD2kM9bC3NEeTBAEtERCQWhlmqMwXFanx3LBZr/7ymu4Rqe18HzO4XhNCmziJXR0RERA0BwyzVOrVGwI//3sGK/VdwJz0PANDM1Rr/7ReEp1u584QnIiIiqjUMs1RrBEHAX9Ep+HDvZd28rh52lpjROxBDOzaBGSf1JyJqtNRqNYqKisQug0yIhYVFrUy/yjBLtSIy7h4++O0yTsakAQDsLM3wes/mGNvNH1YWvJwqEVFjJQgCEhMTkZ6eLnYpZGLkcjkCAgJgYVGzmYwYZqlGriVn4+N9l7HvQhIA7eVWx3Xzx+s9m8FBVX/TbBERkWkqDbJubm5QqVQcakYAAI1Gg/j4eCQkJMDX17dGnwuGWaqWxIx8rPzjCrb/cwsaAZDLgKEdm2BG70fg5WAldnlERGQC1Gq1Lsg6O/PEX9Ln6uqK+Ph4FBcXw9y8+jMDMcySUTJyi7Du4HVsPBKjuzpWn1bu+G/fFgh0txW5OiIiMiWlY2RVKtObS5zEVzq8QK1WM8xS3csvUuPbYzex9s/ryMjT/ufU2d8Rs/sHoaOfk8jVERGRKePQAipPbX0uGGapUmqNgB8ib+PT/VeQkJEPAHjE3Qb/7RuEp1q68T8oIiIiEhXDLJVLEAT8cSkZH+29jKvJ2QAAL3tLzHy6BYa094ZCzhBLRERE4mOYJQOnbqbhw98u45/YewAAB5U5JvdsjlFd/WBpzmm2iIiITN2mTZswY8aMRjElGmexJ50rSVl49ZtTGLb+GP6JvQdLczkm9WyGg2/3wmtPNGWQJSKiRmHs2LGQyWSYOHGiwbrJkydDJpNh7NixetsPHjy4wufz9/eHTCaDTCaDtbU1OnTogB07dtRB5Y0TwyzhTnoe3tpxBv1WHsIfl5KhkMswsosvDr7dC//tFwR7q+qfYUhERCRFPj4+2Lp1K/Ly8nRt+fn52Lx5M3x9fY1+vsWLFyMhIQH//vsvOnfujBdffBFHjx6tzZIbLYbZRqywWIM1B67iyU/+ws7Tt6ERgP5tPPD7G09g2fPBcLezFLtEIiJqQARBQG5hsSiLIAhG1dqhQwf4+Phg165durZdu3bB19cX7du3N/q129rawsPDA4888gjWrl0LKysr/PzzzwbbaTQaNGnSBOvWrdNr//fffyGXyxEbGwsAWLFiBYKDg2FtbQ0fHx9MmjQJ2dnZRtcFANevX8dzzz0Hd3d32NjYoHPnzvjjjz/0tikoKMCsWbPg4+MDpVKJ5s2bY8OGDbr1Fy5cwLPPPgs7OzvY2tri8ccfx/Xr16tVj7E4ZraROnUzDXN2ncO1kpO7QgOcMLt/ENr7OopcGRERNVR5RWq0WrBPlGNfXNwXKgvjYs/48eOxceNGhIWFAQC+/vprjBs3Dn/99VeNajEzM4O5uTkKCwsN1snlcowcORKbN2/G66+/rmsPDw9H9+7d4efnp9tu1apVCAgIwI0bNzBp0iT897//xeeff250PdnZ2RgwYACWLFkCpVKJb7/9FgMHDkR0dLSuF3r06NE4duwYVq1ahZCQEMTExCA1NRUAcOfOHTzxxBPo2bMnDhw4ADs7Oxw5cgTFxcXVeXuMxjDbyGTkFuGDvZew5eQtAICLjQXmP9sKg0K8OM0WERFRGS+//DLmzJmj6w09cuQItm7dWqMwW1hYiOXLlyMjIwNPPvlkuduEhYVh+fLliIuLg6+vLzQaDbZu3Yp58+bptpkxY4buvr+/P95//31MnDixWmE2JCQEISEhusfvvfcedu/ejT179mDKlCm4cuUKtm/fjv3796N3794AgKZNm+q2X7t2Lezt7bF161bdxQ8eeeQRo+uoLobZRkIQBOw5E4/3/ncRqdnavwRHdvHBrH5BcFBZiFwdERE1BlbmClxc3Fe0YxvL1dUVzzzzDDZt2gRBEPDMM8/AxcWlWsefNWsW5s2bh/z8fNjY2OCDDz7AM888U+627dq1Q8uWLbF582bMnj0bBw8eRHJyMoYNG6bb5o8//sCyZctw+fJlZGZmori4GPn5+cjNzTX6imvZ2dl499138csvvyAhIQHFxcXIy8tDXFwcACAqKgoKhQI9evQod/+oqCg8/vjjNbqKV00wzDYCcXdzMe+n8zh0JQUA0NzNBkuHBKNLAK/cRURE9Ucmkxn9Vb/Yxo8fjylTpgDQ9kBW19tvv42xY8fCxsYG7u7uD/02NCwsTBdmN2/ejH79+sHZ2RkAcPPmTTz77LN4/fXXsWTJEjg5OeHw4cN45ZVXUFhYaHSYfeutt7B//3588sknaN68OaysrDB06FDdMAgrK6tK93/Y+romrU8UGaVIrcFXf9/AZ39cRUGxBhZmckzt1Rz/6dEMFmY894+IiOhh+vXrh8LCQshkMvTtW/1eZRcXFzRv3rzK27/00kuYN28eTp8+jZ07d2L9+vW6dadPn4ZGo8Hy5cshl2t/n2/fvr3atR05cgRjx47FkCFDAGh7am/evKlbHxwcDI1Gg4MHD+qGGZTVtm1bfPPNNygqKhKld5ZhtoE6HXsPc3edQ3RSFgCgWzNnLBkSjAAXa5ErIyIikg6FQoFLly7p7lckIyMDUVFRem3Ozs7w8fGp1nH9/f3RrVs3vPLKK1Cr1Rg0aJBuXfPmzVFUVITVq1dj4MCBOHLkiF7YNVZgYCB27dqFgQMHQiaTYf78+dBoNHq1jBkzBuPHj9edABYbG4vk5GQMHz4cU6ZMwerVqzFixAjMmTMH9vb2OH78OLp06YIWLVpUu66qYvdcA5ORV4R5P57D0PVHEZ2UBSdrC6wYHoLwV0MZZImIiKrBzs4OdnZ2lW7z119/oX379nrLokWLanTcsLAwnDlzBkOGDNH7Kj8kJAQrVqzAhx9+iDZt2iA8PBzLli2r9nFWrFgBR0dHdOvWDQMHDkTfvn3RoUMHvW3WrVuHoUOHYtKkSQgKCsJrr72GnJwcANrQfuDAAWRnZ6NHjx7o2LEjvvrqq3rrpZUJxk68JnGZmZmwt7dHRkbGQz+YUiIIAn45l4BFP19ESlYBAGBYxyaYM6AlnKx5ghcREdW//Px8xMTEICAgAJaWnLuc9FX2+TAmr3GYQQNwKy0XC346jz+jtSd4NXWxxpIhwejazFnkyoiIiIjqFsOshBWrNfj6SAw+3X8VeUVqWCjkmNSrGV7v2QxKM+OnICEiIqKGp3Xr1rq5ch/0xRdf6C4KIVUMsxIVdSsdc3adw6WETADaK3gtGRKM5m42IldGREREpuTXX39FUVFRuevc3d3ruZraxzArMVn5RVj++xV8c+wmBAFwUJlj7oCWGNaxCa/gRURERAZKL4HbUDHMSoQgCNh3IQnv7rmAxMx8AMDz7b3xzjMt4WyjFLk6IiIiInEwzEpAfHoeFvx0AX9cSgIA+DursGRIMLo3r94l9YiIiIgaCoZZE1as1uCbY7FY/ns0cgvVMFfIMLFHM0zu1RyW1bjGNBEREVFDwzBros7dzsCc3Wdx/o72BK9Ofo5Y9nwwAt1tRa6MiIiIyHQwzJqYnIJiLP/9CjYdjYFGAOwszTB3QEsM7+QDuZwneBERERGVxTBrQvZfTMLCn84jPkN7gtdz7bww75lWcLXlCV5ERERUPTKZDLt378bgwYPFLqVOyMUugIDEjHxM/O40Xvv2H8Rn5MPHyQrfjO+Cz0a0Z5AlIiISQWJiIqZOnYqmTZtCqVTCx8cHAwcOREREhG4bf39/yGQyHD9+XG/fGTNmoGfPnrrH7777LmQyGSZOnKi3XVRUFGQyGW7evFmXL6XBY5gVkVoj4JujN9F7xUHsvZAIM7kMr/dsht9n9ECPR1zFLo+IiKhRunnzJjp27IgDBw7g448/xrlz57B371706tULkydP1tvW0tISs2bNeuhzWlpaYsOGDbh69Wpdld1oMcyK5EJ8Bp5fdxQL91xAdkExOvg64H/THsOsfkGwsuBMBURE1AAJAlCYI84iCFUuc9KkSZDJZDh58iReeOEFPPLII2jdujVmzpxp0As7YcIEHD9+HL/++mulz9miRQv06tUL77zzTpXrmDt3LkJDQw3aQ0JCsHjxYgDAqVOn0KdPH7i4uMDe3h49evRAZGRklY/xoFmzZuGRRx6BSqVC06ZNMX/+fIOrh/3888/o3LkzLC0t4eLigiFDhujWFRQUYNasWfDx8YFSqUTz5s2xYcOGatdTFRwzW89yC4ux8o+r2HA4BmqNAFtLM8zqF4SXuvjyBC8iImrYinKBpV7iHHtuPGBh/dDN0tLSsHfvXixZsgTW1obbOzg46D0OCAjAxIkTMWfOHPTr1w9yecX9hB988AE6d+6Mf/75B506dXpoLWFhYVi2bBmuX7+OZs2aAQAuXLiAs2fP4ocffgAAZGVlYcyYMVi9ejUEQcDy5csxYMAAXL16Fba2xs+AZGtri02bNsHLywvnzp3Da6+9BltbW/z3v/8FAPzyyy8YMmQI3nnnHXz77bcoLCzUC/KjR4/GsWPHsGrVKoSEhCAmJgapqalG12EMhtl69OflZMz78TzupOcBAJ5p64mFz7aCm52lyJURERERAFy7dg2CICAoKKjK+8ybNw8bN25EeHg4Ro0aVeF2HTp0wPDhwzFr1iy9sbcVad26NUJCQrB582bMnz8fABAeHo7Q0FA0b94cAPDkk0/q7fPll1/CwcEBBw8exLPPPlvl11D2tZTy9/fHW2+9ha1bt+rC7JIlSzBixAgsWrRIt11ISAgA4MqVK9i+fTv279+P3r17AwCaNm1qdA3GYpitB8mZ+Vj080X8ci4BAODtYIX3B7dBryA3kSsjIiKqR+YqbQ+pWMeuAsGI4QilXF1d8dZbb2HBggV48cUXK932/fffR8uWLfH777/Dze3hOSAsLAxff/015s+fD0EQsGXLFsycOVO3PikpCfPmzcNff/2F5ORkqNVq5ObmIi4uzujXAQDbtm3DqlWrcP36dWRnZ6O4uBh2dna69VFRUXjttdfK3TcqKgoKhQI9evSo1rGri2G2joWfiMUHv11GVn4xFHIZXn0sANN7B0JlwbeeiIgaGZmsSl/1iykwMBAymQyXL182ar+ZM2fi888/x+eff17pds2aNcNrr72G2bNnV2ks6ciRIzFr1ixERkYiLy8Pt27d0gvMY8aMwd27d/HZZ5/Bz88PSqUSXbt2RWFhoVH1A8CxY8cQFhaGRYsWoW/fvrC3t8fWrVuxfPly3TZWVlYV7l/ZurrEE8Dq2Pk7GcjKL0ZIE3vsmdIdcwa0ZJAlIiIyUU5OTujbty/Wrl2LnJwcg/Xp6enl7mdjY4P58+djyZIlyMrKqvQYCxYswJUrV7B169aH1tOkSRP06NED4eHhCA8PR58+ffR6dI8cOYJp06ZhwIABaN26NZRKZbXHqB49ehR+fn5455130KlTJwQGBiI2NlZvm7Zt21Y4RCI4OBgajQYHDx6s1vGri2G2js3u1xLvD26DXZO6o7WXvdjlEBER0UOsXbsWarUaXbp0wQ8//ICrV6/i0qVLWLVqFbp27VrhfhMmTIC9vT02b95c6fO7u7tj5syZWLVqVZXqCQsLw9atW7Fjxw6EhYXprQsMDMR3332HS5cu4cSJEwgLC6t2D2lgYCDi4uKwdetWXL9+HatWrcLu3bv1tlm4cCG2bNmChQsX4tKlSzh37hw+/PBDANoxtmPGjMH48ePx448/IiYmBn/99Re2b99erXqqimG2jtmrzPHyo35QcKYCIiIiSWjatCkiIyPRq1cvvPnmm2jTpg369OmDiIgIrFu3rsL9zM3N8d577yE/P/+hx3jrrbdgY2NTpXqGDh2Ku3fvIjc31+AqXhs2bMC9e/fQoUMHjBo1CtOmTavSWNzyDBo0CG+88QamTJmCdu3a4ejRo7oTz0r17NkTO3bswJ49e9CuXTs8+eSTOHnypG79unXrMHToUEyaNAlBQUF47bXXyu3hrk0yoTojnSUsMzMT9vb2yMjI0BvQTERERLUrPz8fMTExCAgIgKUlZ+4hfZV9PozJa+yZJSIiIiLJYpglIiIiagSWLl0KGxubcpf+/fuLXV618bR6IiIiokZg4sSJGD58eLnrxJpWqzYwzBIRERE1Ak5OTnBychK7jFrHYQZERERUpxrZueZURbX1uWCYJSIiojphbm4OAMjNzRW5EjJFpVcpUygUNXoeDjMgIiKiOqFQKODg4IDk5GQAgEqlgkzGedcJ0Gg0SElJgUqlgplZzeIowywRERHVGQ8PDwDQBVqiUnK5HL6+vjX+A4dhloiIiOqMTCaDp6cn3NzcUFRUJHY5ZEIsLCwgl9d8xCvDLBEREdU5hUJR47GRROXhCWBEREREJFkMs0REREQkWQyzRERERCRZjW7MbOkEvZmZmSJXQkRERETlKc1pVbmwQqMLs1lZWQAAHx8fkSshIiIiospkZWXB3t6+0m1kQiO7xpxGo0F8fDxsbW3rZeLmzMxM+Pj44NatW7Czs6vz4zVEfA9rhu9fzfE9rDm+hzXD96/m+B7WTH2/f4IgICsrC15eXg+dvqvR9czK5XI0adKk3o9rZ2fHfzw1xPewZvj+1Rzfw5rje1gzfP9qju9hzdTn+/ewHtlSPAGMiIiIiCSLYZaIiIiIJIthto4plUosXLgQSqVS7FIki+9hzfD9qzm+hzXH97Bm+P7VHN/DmjHl96/RnQBGRERERA0He2aJiIiISLIYZomIiIhIshhmiYiIiEiyGGaJiIiISLIYZuvY2rVr4e/vD0tLS4SGhuLkyZNilyQZy5YtQ+fOnWFraws3NzcMHjwY0dHRYpclWR988AFkMhlmzJghdimScufOHbz88stwdnaGlZUVgoOD8c8//4hdliSo1WrMnz8fAQEBsLKyQrNmzfDee+9V6VrrjdWhQ4cwcOBAeHl5QSaT4ccff9RbLwgCFixYAE9PT1hZWaF37964evWqOMWaoMrev6KiIsyaNQvBwcGwtraGl5cXRo8ejfj4ePEKNkEP+wyWNXHiRMhkMqxcubLe6isPw2wd2rZtG2bOnImFCxciMjISISEh6Nu3L5KTk8UuTRIOHjyIyZMn4/jx49i/fz+Kiorw9NNPIycnR+zSJOfUqVP44osv0LZtW7FLkZR79+6he/fuMDc3x2+//YaLFy9i+fLlcHR0FLs0Sfjwww+xbt06rFmzBpcuXcKHH36Ijz76CKtXrxa7NJOVk5ODkJAQrF27ttz1H330EVatWoX169fjxIkTsLa2Rt++fZGfn1/PlZqmyt6/3NxcREZGYv78+YiMjMSuXbsQHR2NQYMGiVCp6XrYZ7DU7t27cfz4cXh5edVTZZUQqM506dJFmDx5su6xWq0WvLy8hGXLlolYlXQlJycLAISDBw+KXYqkZGVlCYGBgcL+/fuFHj16CNOnTxe7JMmYNWuW8Nhjj4ldhmQ988wzwvjx4/Xann/+eSEsLEykiqQFgLB7927dY41GI3h4eAgff/yxri09PV1QKpXCli1bRKjQtD34/pXn5MmTAgAhNja2foqSmIrew9u3bwve3t7C+fPnBT8/P+HTTz+t99rKYs9sHSksLMTp06fRu3dvXZtcLkfv3r1x7NgxESuTroyMDACAk5OTyJVIy+TJk/HMM8/ofRapavbs2YNOnTph2LBhcHNzQ/v27fHVV1+JXZZkdOvWDREREbhy5QoA4MyZMzh8+DD69+8vcmXSFBMTg8TERL1/y/b29ggNDeXvlWrKyMiATCaDg4OD2KVIhkajwahRo/D222+jdevWYpcDADATu4CGKjU1FWq1Gu7u7nrt7u7uuHz5skhVSZdGo8GMGTPQvXt3tGnTRuxyJGPr1q2IjIzEqVOnxC5Fkm7cuIF169Zh5syZmDt3Lk6dOoVp06bBwsICY8aMEbs8kzd79mxkZmYiKCgICoUCarUaS5YsQVhYmNilSVJiYiIAlPt7pXQdVV1+fj5mzZqFkSNHws7OTuxyJOPDDz+EmZkZpk2bJnYpOgyzJAmTJ0/G+fPncfjwYbFLkYxbt25h+vTp2L9/PywtLcUuR5I0Gg06deqEpUuXAgDat2+P8+fPY/369QyzVbB9+3aEh4dj8+bNaN26NaKiojBjxgx4eXnx/SNRFRUVYfjw4RAEAevWrRO7HMk4ffo0PvvsM0RGRkImk4ldjg6HGdQRFxcXKBQKJCUl6bUnJSXBw8NDpKqkacqUKfjf//6HP//8E02aNBG7HMk4ffo0kpOT0aFDB5iZmcHMzAwHDx7EqlWrYGZmBrVaLXaJJs/T0xOtWrXSa2vZsiXi4uJEqkha3n77bcyePRsjRoxAcHAwRo0ahTfeeAPLli0TuzRJKv3dwd8rNVMaZGNjY7F//372yhrh77//RnJyMnx9fXW/V2JjY/Hmm2/C399ftLoYZuuIhYUFOnbsiIiICF2bRqNBREQEunbtKmJl0iEIAqZMmYLdu3fjwIEDCAgIELskSXnqqadw7tw5REVF6ZZOnTohLCwMUVFRUCgUYpdo8rp3724wHdyVK1fg5+cnUkXSkpubC7lc/9eMQqGARqMRqSJpCwgIgIeHh97vlczMTJw4cYK/V6qoNMhevXoVf/zxB5ydncUuSVJGjRqFs2fP6v1e8fLywttvv419+/aJVheHGdShmTNnYsyYMejUqRO6dOmClStXIicnB+PGjRO7NEmYPHkyNm/ejJ9++gm2tra6MWH29vawsrISuTrTZ2trazC+2NraGs7Ozhx3XEVvvPEGunXrhqVLl2L48OE4efIkvvzyS3z55ZdilyYJAwcOxJIlS+Dr64vWrVvj33//xYoVKzB+/HixSzNZ2dnZuHbtmu5xTEwMoqKi4OTkBF9fX8yYMQPvv/8+AgMDERAQgPnz58PLywuDBw8Wr2gTUtn75+npiaFDhyIyMhL/+9//oFardb9XnJycYGFhIVbZJuVhn8EH/wAwNzeHh4cHWrRoUd+l3ifqXAqNwOrVqwVfX1/BwsJC6NKli3D8+HGxS5IMAOUuGzduFLs0yeLUXMb7+eefhTZt2ghKpVIICgoSvvzyS7FLkozMzExh+vTpgq+vr2BpaSk0bdpUeOedd4SCggKxSzNZf/75Z7n/740ZM0YQBO30XPPnzxfc3d0FpVIpPPXUU0J0dLS4RZuQyt6/mJiYCn+v/Pnnn2KXbjIe9hl8kClMzSUTBF6KhYiIiIikiWNmiYiIiEiyGGaJiIiISLIYZomIiIhIshhmiYiIiEiyGGaJiIiISLIYZomIiIhIshhmiYiIiEiyGGaJiIiISLIYZomIGimZTIYff/xR7DKIiGqEYZaISARjx46FTCYzWPr16yd2aUREkmImdgFERI1Vv379sHHjRr02pVIpUjVERNLEnlkiIpEolUp4eHjoLY6OjgC0QwDWrVuH/v37w8rKCk2bNsXOnTv19j937hyefPJJWFlZwdnZGRMmTEB2drbeNl9//TVat24NpVIJT09PTJkyRW99amoqhgwZApVKhcDAQOzZs6duXzQRUS1jmCUiMlHz58/HCy+8gDNnziAsLAwjRozApUuXAAA5OTno27cvHB0dcerUKezYsQN//PGHXlhdt24dJk+ejAkTJuDcuXPYs2cPmjdvrneMRYsWYfjw4Th79iwGDBiAsLAwpKWl1evrJCKqCZkgCILYRRARNTZjx47F999/D0tLS732uXPnYu7cuZDJZJg4cSLWrVunW/foo4+iQ4cO+Pzzz/HVV19h1qxZuHXrFqytrQEAv/76KwYOHIj4+Hi4u7vD29sb48aNw/vvv19uDTKZDPPmzcN7770HQBuQbWxs8Ntvv3HsLhFJBsfMEhGJpFevXnphFQCcnJx097t27aq3rmvXroiKigIAXLp0CSEhIbogCwDdu3eHRqNBdHQ0ZDIZ4uPj8dRTT1VaQ9u2bXX3ra2tYWdnh+Tk5Oq+JCKiescwS0QkEmtra4Ov/WuLlZVVlbYzNzfXeyyTyaDRaOqiJCKiOsExs0REJur48eMGj1u2bAkAaNmyJc6cOYOcnBzd+iNHjkAul6NFixawtbWFv78/IiIi6rVmIqL6xp5ZIiKRFBQUIDExUa/NzMwMLi4uAIAdO3agU6dOeOyxxxAeHo6TJ09iw4YNAICwsDAsXLgQY8aMwbvvvouUlBRMnToVo0aNgru7OwDg3XffxcSJE+Hm5ob+/fsjKysLR44cwdSpU+v3hRIR1SGGWSIikezduxeenp56bS1atMDly5cBaGca2Lp1KyZNmgRPT09s2bIFrVq1AgCoVCrs27cP06dPR+fOnaFSqfDCCy9gxYoVuucaM2YM8vPz8emnn+Ktt96Ci4sLhg4dWn8vkIioHnA2AyIiEySTybB7924MHjxY7FKIiEwax8wSERERkWQxzBIRERGRZHHMLBGRCeIIMCKiqmHPLBERERFJFsMsEREREUkWwywRERERSRbDLBERERFJFsMsEREREUkWwywRERERSRbDLBERERFJFsMsEREREUnW/wMYAPpLOkm0YgAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "\n",
        "\n",
        "plt.figure(figsize=(8,5))\n",
        "plt.plot(history_mlp_cifar.history['val_accuracy'], label='MLP val_acc')\n",
        "plt.plot(history_cnn_cifar.history['val_accuracy'], label='CNN val_acc')\n",
        "plt.title('Validation Accuracy on CIFAR-10')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}