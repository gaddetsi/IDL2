{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86e5d3fe",
   "metadata": {},
   "source": [
    "# Code for Task 2.1.c and Task 2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb0b5f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, Input, BatchNormalization, Activation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.python.framework.ops import SymbolicTensor\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.src import ops\n",
    "from task2_1_a import load_data, to_categorical, common_sense_mse\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "import os, sys\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from task2_1_a import load_data\n",
    "from task2_1_c_and_2_2 import h_numerical_cs_mse, m_numerical_cs_mse, common_sense_mse_12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "266c7c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "EPOCHS = 1000 # high number since we use early stopping\n",
    "\n",
    "@tf.keras.utils.register_keras_serializable()\n",
    "def common_sense_mse_12(y_true, y_pred):\n",
    "    \"\"\"common sense mse from task 2.1.a with num_classes = 12\"\"\"\n",
    "    return common_sense_mse(y_true, y_pred, num_classes=12)\n",
    "\n",
    "def hour_labels_to_sin_cos(y):\n",
    "    \"\"\"\n",
    "    Convert (hour, minute) → [cos, sin] of hour angle.\n",
    "    This encoding handles the circular nature of time.\n",
    "    \"\"\"\n",
    "    hours_float = y[:, 0] + y[:, 1] / 60.0\n",
    "    angle = 2 * np.pi * hours_float / 12.0  # full rotation = 12 hours\n",
    "    y_cos = np.cos(angle)\n",
    "    y_sin = np.sin(angle)\n",
    "    return np.stack([y_cos, y_sin], axis=1)  # shape: (N, 2)\n",
    "\n",
    "def minute_labels_to_sin_cos(y):\n",
    "    \"\"\"\n",
    "    Convert (hour, minute) → [cos, sin] of minute angle.\n",
    "    This encoding handles the circular nature of time.\n",
    "    \"\"\"\n",
    "    minutes_float = y[:, 1]\n",
    "    angle = 2 * np.pi * minutes_float / 60.0  # full rotation = 60 minutes\n",
    "    y_cos = np.cos(angle)\n",
    "    y_sin = np.sin(angle)\n",
    "    return np.stack([y_cos, y_sin], axis=1)  # shape: (N, 2)\n",
    "\n",
    "\n",
    "def build_cnn_multi_class_reg(input_shape):\n",
    "    \"\"\"CNN with multi-headed regression (two paths for hours and minutes).\"\"\"\n",
    "    inputs = Input(shape=input_shape)\n",
    "    \n",
    "    # First conv block\n",
    "    x1 = Conv2D(32, (3, 3), padding='same')(inputs)\n",
    "    x2 = Conv2D(32, (3, 3), padding='same')(inputs)\n",
    "    x1 = BatchNormalization()(x1)\n",
    "    x2 = BatchNormalization()(x2)\n",
    "    x1 = Activation('relu')(x1)\n",
    "    x2 = Activation('relu')(x2)\n",
    "    x1 = Conv2D(32, (3, 3), padding='same')(x1)\n",
    "    x2 = Conv2D(32, (3, 3), padding='same')(x2)\n",
    "    x1 = BatchNormalization()(x1)\n",
    "    x2 = BatchNormalization()(x2)\n",
    "    x1 = Activation('relu')(x1)\n",
    "    x2 = Activation('relu')(x2)\n",
    "    x1 = MaxPooling2D((2, 2))(x1)\n",
    "    x2 = MaxPooling2D((2, 2))(x2)\n",
    "    x1 = Dropout(0.2)(x1)\n",
    "    x2 = Dropout(0.2)(x2)\n",
    "    \n",
    "    # Second conv block\n",
    "    x1 = Conv2D(64, (3, 3), padding='same')(x1)\n",
    "    x2 = Conv2D(64, (3, 3), padding='same')(x2)\n",
    "    x1 = BatchNormalization()(x1)\n",
    "    x2 = BatchNormalization()(x2)\n",
    "    x1 = Activation('relu')(x1)\n",
    "    x2 = Activation('relu')(x2)\n",
    "    x1 = Conv2D(64, (3, 3), padding='same')(x1)\n",
    "    x2 = Conv2D(64, (3, 3), padding='same')(x2)\n",
    "    x1 = BatchNormalization()(x1)\n",
    "    x2 = BatchNormalization()(x2)\n",
    "    x1 = Activation('relu')(x1)\n",
    "    x2 = Activation('relu')(x2)\n",
    "    x1 = MaxPooling2D((2, 2))(x1)\n",
    "    x2 = MaxPooling2D((2, 2))(x2)\n",
    "    x1 = Dropout(0.2)(x1)\n",
    "    x2 = Dropout(0.2)(x2)\n",
    "\n",
    "    # Third conv block\n",
    "    x1 = Conv2D(128, (3, 3), padding='same')(x1)\n",
    "    x1 = BatchNormalization()(x1)\n",
    "    x1 = Activation('relu')(x1)\n",
    "    x1 = MaxPooling2D((2, 2))(x1)\n",
    "    x1 = Dropout(0.3)(x1)\n",
    "\n",
    "    x2 = Conv2D(128, (3, 3), padding='same')(x2)\n",
    "    x2 = BatchNormalization()(x2)\n",
    "    x2 = Activation('relu')(x2)\n",
    "    x2 = MaxPooling2D((2, 2))(x2)\n",
    "    x2 = Dropout(0.3)(x2)\n",
    "\n",
    "    # Dense layers\n",
    "    x1 = Flatten()(x1)\n",
    "    x1 = Dense(128)(x1)\n",
    "    x1 = BatchNormalization()(x1)\n",
    "    x1 = Activation('relu')(x1)\n",
    "    x1 = Dropout(0.4)(x1)\n",
    "\n",
    "    x2 = Flatten()(x2)\n",
    "    x2 = Dense(128)(x2)\n",
    "    x2 = BatchNormalization()(x2)\n",
    "    x2 = Activation('relu')(x2)\n",
    "    x2 = Dropout(0.4)(x2)\n",
    "\n",
    "    x1 = Flatten()(x1)\n",
    "    x1 = Dense(256)(x1)\n",
    "    x1 = BatchNormalization()(x1)\n",
    "    x1 = Activation('relu')(x1)\n",
    "    x1 = Dropout(0.4)(x1)\n",
    "\n",
    "    x2 = Flatten()(x2)\n",
    "    x2 = Dense(256)(x2)\n",
    "    x2 = BatchNormalization()(x2)\n",
    "    x2 = Activation('relu')(x2)\n",
    "    x2 = Dropout(0.4)(x2)\n",
    "\n",
    "    x1 = Dense(128)(x1)\n",
    "    x1 = BatchNormalization()(x1)\n",
    "    x1 = Activation('relu')(x1)\n",
    "    x1 = Dropout(0.3)(x1)\n",
    "\n",
    "    x2 = Dense(128)(x2)\n",
    "    x2 = BatchNormalization()(x2)\n",
    "    x2 = Activation('relu')(x2)\n",
    "    x2 = Dropout(0.3)(x2)\n",
    "\n",
    "    # two output layers for hours and minutes\n",
    "    # hour has 12 output nodes for every hour class (0-11) with softmax activation\n",
    "    hour_output = Dense(12, activation='softmax')(x1)\n",
    "    minute_output = Dense(1, activation='linear')(x2)\n",
    "\n",
    "    return keras.Model(inputs, [hour_output, minute_output], name=\"cnn_multi_class_regression\")\n",
    "\n",
    "\n",
    "\n",
    "def build_cnn_multi_sin_cos(input_shape):\n",
    "    \"\"\"CNN for periodic regression (predicting sin/cos of time angle).\"\"\"\n",
    "    inputs = Input(shape=input_shape)\n",
    "    \n",
    "    # First conv block\n",
    "    x1 = Conv2D(32, (3, 3), padding='same')(inputs)\n",
    "    x2 = Conv2D(32, (3, 3), padding='same')(inputs)\n",
    "    x1 = BatchNormalization()(x1)\n",
    "    x2 = BatchNormalization()(x2)\n",
    "    x1 = Activation('relu')(x1)\n",
    "    x2 = Activation('relu')(x2)\n",
    "    x1 = Conv2D(32, (3, 3), padding='same')(x1)\n",
    "    x2 = Conv2D(32, (3, 3), padding='same')(x2)\n",
    "    x1 = BatchNormalization()(x1)\n",
    "    x2 = BatchNormalization()(x2)\n",
    "    x1 = Activation('relu')(x1)\n",
    "    x2 = Activation('relu')(x2)\n",
    "    x1 = MaxPooling2D((2, 2))(x1)\n",
    "    x2 = MaxPooling2D((2, 2))(x2)\n",
    "    x1 = Dropout(0.2)(x1)\n",
    "    x2 = Dropout(0.2)(x2)\n",
    "    \n",
    "    # Second conv block\n",
    "    x1 = Conv2D(64, (3, 3), padding='same')(x1)\n",
    "    x2 = Conv2D(64, (3, 3), padding='same')(x2)\n",
    "    x1 = BatchNormalization()(x1)\n",
    "    x2 = BatchNormalization()(x2)\n",
    "    x1 = Activation('relu')(x1)\n",
    "    x2 = Activation('relu')(x2)\n",
    "    x1 = Conv2D(64, (3, 3), padding='same')(x1)\n",
    "    x2 = Conv2D(64, (3, 3), padding='same')(x2)\n",
    "    x1 = BatchNormalization()(x1)\n",
    "    x2 = BatchNormalization()(x2)\n",
    "    x1 = Activation('relu')(x1)\n",
    "    x2 = Activation('relu')(x2)\n",
    "    x1 = MaxPooling2D((2, 2))(x1)\n",
    "    x2 = MaxPooling2D((2, 2))(x2)\n",
    "    x1 = Dropout(0.2)(x1)\n",
    "    x2 = Dropout(0.2)(x2)\n",
    "\n",
    "    # Third conv block\n",
    "    x1 = Conv2D(128, (3, 3), padding='same')(x1)\n",
    "    x1 = BatchNormalization()(x1)\n",
    "    x1 = Activation('relu')(x1)\n",
    "    x1 = MaxPooling2D((2, 2))(x1)\n",
    "    x1 = Dropout(0.3)(x1)\n",
    "\n",
    "    x2 = Conv2D(128, (3, 3), padding='same')(x2)\n",
    "    x2 = BatchNormalization()(x2)\n",
    "    x2 = Activation('relu')(x2)\n",
    "    x2 = MaxPooling2D((2, 2))(x2)\n",
    "    x2 = Dropout(0.3)(x2)\n",
    "\n",
    "    # Dense layers\n",
    "    x1 = Flatten()(x1)\n",
    "    x1 = Dense(128)(x1)\n",
    "    x1 = BatchNormalization()(x1)\n",
    "    x1 = Activation('relu')(x1)\n",
    "    x1 = Dropout(0.4)(x1)\n",
    "\n",
    "    x2 = Flatten()(x2)\n",
    "    x2 = Dense(128)(x2)\n",
    "    x2 = BatchNormalization()(x2)\n",
    "    x2 = Activation('relu')(x2)\n",
    "    x2 = Dropout(0.4)(x2)\n",
    "\n",
    "    x1 = Flatten()(x1)\n",
    "    x1 = Dense(256)(x1)\n",
    "    x1 = BatchNormalization()(x1)\n",
    "    x1 = Activation('relu')(x1)\n",
    "    x1 = Dropout(0.4)(x1)\n",
    "\n",
    "    x2 = Flatten()(x2)\n",
    "    x2 = Dense(256)(x2)\n",
    "    x2 = BatchNormalization()(x2)\n",
    "    x2 = Activation('relu')(x2)\n",
    "    x2 = Dropout(0.4)(x2)\n",
    "\n",
    "    x1 = Dense(128)(x1)\n",
    "    x1 = BatchNormalization()(x1)\n",
    "    x1 = Activation('relu')(x1)\n",
    "    x1 = Dropout(0.3)(x1)\n",
    "\n",
    "    x2 = Dense(128)(x2)\n",
    "    x2 = BatchNormalization()(x2)\n",
    "    x2 = Activation('relu')(x2)\n",
    "    x2 = Dropout(0.3)(x2)\n",
    "\n",
    "    # Output layer: 2 nodes for cos and sin, bounded by tanh\n",
    "    hours_output = Dense(12, activation='softmax')(x1)\n",
    "    minutes_output = Dense(2, activation='tanh')(x2)\n",
    "\n",
    "    return keras.Model(inputs, [hours_output, minutes_output], name=\"multi_cnn_periodic\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d5ac367",
   "metadata": {},
   "source": [
    "# Run experiment 2.1.c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d16fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('saved_models', exist_ok=True)\n",
    "\n",
    "# multi class+regression\n",
    "seed=42\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "keras.utils.set_random_seed(seed)\n",
    "\n",
    "X_train, y_train, X_val, y_val, X_test, y_test, input_shape = load_data(seed=seed, easy=False)\n",
    "\n",
    "print(X_train.shape, X_val.shape, X_test.shape)\n",
    "\n",
    "y_train1 = to_categorical(y_train, 12)\n",
    "y_val1 = to_categorical(y_val, 12)\n",
    "y_test1 = to_categorical(y_test, 12)\n",
    "\n",
    "img_rows, img_cols = X_train.shape[1], X_train.shape[2]\n",
    "input_shape = (img_rows, img_cols, 1)\n",
    "print(input_shape)\n",
    "\n",
    "# regression model with two outputs\n",
    "model = build_cnn_multi_class_reg(input_shape)\n",
    "# compile with common sense mse for categorical hours and mse for priodic regession minutes.\n",
    "model.compile(loss=[common_sense_mse_12, \"mse\"],\n",
    "            loss_weights=[1.0, 0.5],\n",
    "            optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n",
    "            metrics=['accuracy','accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# same Callback as task 2.1.a\n",
    "callbacks = [\n",
    "    keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_loss', patience=5, factor=0.5, verbose=1, min_lr=1e-7\n",
    "    ),\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss', patience=15, verbose=1, restore_best_weights=True\n",
    "    )\n",
    "]\n",
    "#  fit model\n",
    "model.fit(X_train, [y_train1, y_train[:, 1]],\n",
    "        batch_size=BATCH_SIZE,\n",
    "        epochs=EPOCHS,\n",
    "        verbose=1,\n",
    "        callbacks=callbacks,\n",
    "        validation_data=(X_val, [y_val1, y_val[:, 1]]))\n",
    "# save model\n",
    "model.save('saved_models/multi_class_regression.keras')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa26c3f",
   "metadata": {},
   "source": [
    "# Run experiment 2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab97d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# periodic regression\n",
    "seed=42\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "keras.utils.set_random_seed(seed)\n",
    "\n",
    "X_train, y_train, X_val, y_val, X_test, y_test, input_shape = load_data(seed=42, easy=False)\n",
    "\n",
    "print(X_train.shape, X_val.shape, X_test.shape)\n",
    "\n",
    "y_train_m = minute_labels_to_sin_cos(y_train)\n",
    "y_val_m = minute_labels_to_sin_cos(y_val)\n",
    "y_test_m = minute_labels_to_sin_cos(y_test)\n",
    "\n",
    "y_train_h = to_categorical(y_train, 12)\n",
    "y_val_h = to_categorical(y_val, 12)\n",
    "y_test_h = to_categorical(y_test, 12)\n",
    "\n",
    "img_rows, img_cols = X_train.shape[1], X_train.shape[2]\n",
    "input_shape = (img_rows, img_cols, 1)\n",
    "print(input_shape)\n",
    "\n",
    "# regression model with two outputs\n",
    "model = build_cnn_multi_sin_cos(input_shape)\n",
    "# compile with common sense mse for categorical hours and mse for priodic regession minutes.\n",
    "model.compile(loss=[common_sense_mse_12, \"mse\"],\n",
    "            loss_weights=[1.0, 0.5],\n",
    "            optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n",
    "            metrics=['accuracy','accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# same Callback as task 2.1.a\n",
    "callbacks = [\n",
    "    keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_loss', patience=5, factor=0.5, verbose=1, min_lr=1e-7\n",
    "    ),\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss', patience=15, verbose=1, restore_best_weights=True\n",
    "    )\n",
    "]\n",
    "# fit model\n",
    "model.fit(X_train, [y_train_h, y_train_m],\n",
    "        batch_size=BATCH_SIZE,\n",
    "        epochs=EPOCHS,\n",
    "        verbose=1,\n",
    "        callbacks=callbacks,\n",
    "        validation_data=(X_val, [y_val_h, y_val_m]))\n",
    "#  save model\n",
    "model.save('saved_models/multi_regression_sin_cos.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "995f2477",
   "metadata": {},
   "source": [
    "# Plot results from both experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec7fedc",
   "metadata": {},
   "source": [
    "get models: multi_class_regression is from 2.1.c and multi_regression_sin_cos is from 2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c034a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_models():\n",
    "    model_list= [\"multi_class_regression\",\"multi_regression_sin_cos\"]\n",
    "    return model_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d503b0",
   "metadata": {},
   "source": [
    "plot results and metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc285e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_error_histogram(errors, model_name, save_path=None):\n",
    "    \"\"\"Plot histogram of prediction errors.\"\"\"\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.hist(errors, bins=50, edgecolor='black', alpha=0.7)\n",
    "    plt.xlabel('Absolute Error (minutes)', fontsize=12)\n",
    "    plt.ylabel('Frequency', fontsize=12)\n",
    "    plt.title(f'{model_name} - Error Distribution', fontsize=14, fontweight='bold')\n",
    "    plt.axvline(np.mean(errors), color='r', linestyle='--', linewidth=2, label=f'Mean: {np.mean(errors):.1f} min')\n",
    "    plt.axvline(np.median(errors), color='g', linestyle='--', linewidth=2, label=f'Median: {np.median(errors):.1f} min')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "def sin_cos_to_hours(sin_cos_predictions):\n",
    "    \"\"\"Convert [cos, sin] predictions back to hours (0-12).\"\"\"\n",
    "    cos_vals = sin_cos_predictions[:, 0]\n",
    "    sin_vals = sin_cos_predictions[:, 1]\n",
    "    angles = np.arctan2(sin_vals, cos_vals)  # arctan2(sin, cos)\n",
    "    angles = (angles % (2 * np.pi))  # ensure positive angles\n",
    "    hours = angles * 12 / (2 * np.pi)  # convert to hours\n",
    "    return hours\n",
    "\n",
    "def sin_cos_to_minutes(sin_cos_predictions):\n",
    "    \"\"\"Convert [cos, sin] predictions back to minutes (0-59).\"\"\"\n",
    "    cos_vals = sin_cos_predictions[:, 0]\n",
    "    sin_vals = sin_cos_predictions[:, 1]\n",
    "    angles = np.arctan2(sin_vals, cos_vals)  # arctan2(sin, cos)\n",
    "    angles = (angles % (2 * np.pi))  # ensure positive angles\n",
    "    minutes = angles * 59 / (2 * np.pi)  # convert to minutes\n",
    "    return minutes\n",
    "\n",
    "def plot_predictions_vs_true(pred, true, model_name, save_path=None):\n",
    "    \"\"\"Scatter plot of predictions vs true values.\"\"\"\n",
    "    # Scale back to original values and to decimal hours\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.scatter(true, pred, alpha=0.3, s=10)\n",
    "    plt.plot([0, 12], [0, 12], 'r--', linewidth=2, label='Perfect prediction')\n",
    "    plt.xlabel('True Time (hours)', fontsize=12)\n",
    "    plt.ylabel('Predicted Time (hours)', fontsize=12)\n",
    "    plt.title(f'{model_name} - Predictions vs True Values', fontsize=14, fontweight='bold')\n",
    "    plt.xlim([0, 12])\n",
    "    plt.ylim([0, 12])\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "def get_hours_minutes(hours, minutes):\n",
    "    \"\"\"Convert one-hot or sin-cos encoded hours and minutes to numerical hours and minutes.\"\"\"\n",
    "    hours_ = hours\n",
    "    if hours_.shape[1] == 12:\n",
    "        hours_ = np.argmax(hours_, axis=1).reshape(-1, 1)\n",
    "\n",
    "    minutes_ = minutes\n",
    "    if minutes_.shape[1] == 2:\n",
    "        minutes_ = sin_cos_to_minutes(minutes_).reshape(-1, 1)\n",
    "\n",
    "    return hours_, minutes_\n",
    "\n",
    "def to_decimal(y):\n",
    "    \"\"\"Convert split hours and minutes to decimal hours.\"\"\"\n",
    "    hours = y[0]\n",
    "    minutes = y[1]\n",
    "    hours, minutes = get_hours_minutes(hours, minutes)\n",
    "\n",
    "    decimal_hours = hours + (minutes / 60)\n",
    "    return decimal_hours\n",
    "\n",
    "def split_to_diff_min(pred_time, true_time):\n",
    "    \"\"\"Calculate absolute difference in minutes between predicted and true times.\"\"\"\n",
    "    # if hours are one-hot encoded, convert to numerical\n",
    "    hours: np.ndarray = pred_time[0]\n",
    "    minutes: np.ndarray = pred_time[1]\n",
    "    true_hours: np.ndarray = true_time[0]\n",
    "    true_minutes: np.ndarray = true_time[1]\n",
    "    hours, minutes = get_hours_minutes(hours, minutes)\n",
    "    true_hours, true_minutes = get_hours_minutes(true_hours, true_minutes)\n",
    "\n",
    "    # convert time to total minutes\n",
    "    pred_total_min = (hours * 60) + minutes\n",
    "    true_total_min = (true_hours * 60) + true_minutes\n",
    "\n",
    "    # common sense loss in minutes\n",
    "    diff_min = np.abs(pred_total_min - true_total_min)\n",
    "    csl = np.minimum(diff_min, 720 - diff_min)\n",
    "\n",
    "    return csl\n",
    "\n",
    "def print_metrics(pred_time, true_time, model_name):\n",
    "    \"\"\"Print comprehensive evaluation metrics.\"\"\"\n",
    "    diff_min = split_to_diff_min(pred_time, true_time)\n",
    "\n",
    "    mean_err = np.mean(diff_min)\n",
    "    median_err = np.median(diff_min)\n",
    "    std_err = np.std(diff_min)\n",
    "    max_err = np.max(diff_min)\n",
    "    \n",
    "    within_0 = np.mean(diff_min <= 0) * 100\n",
    "    within_1 = np.mean(diff_min <= 1) * 100\n",
    "    within_5 = np.mean(diff_min <= 5) * 100\n",
    "    within_10 = np.mean(diff_min <= 10) * 100\n",
    "    within_15 = np.mean(diff_min <= 15) * 100\n",
    "    within_30 = np.mean(diff_min <= 30) * 100\n",
    "    \n",
    "    print(f\"\\n{'=' * 80}\")\n",
    "    print(f\"{model_name} - TEST SET RESULTS\")\n",
    "    print(f\"{'=' * 80}\")\n",
    "    print(f\"Mean Absolute Error:    {mean_err:.2f} minutes\")\n",
    "    print(f\"Median Absolute Error:  {median_err:.2f} minutes\")\n",
    "    print(f\"Std Deviation:          {std_err:.2f} minutes\")\n",
    "    print(f\"Max Error:              {max_err:.2f} minutes\")\n",
    "    print(f\"\\nAccuracy within thresholds:\")\n",
    "    print(f\"  Within 0 minutes:     {within_0:.1f}%\")\n",
    "    print(f\"  Within 1 minute:      {within_1:.1f}%\")\n",
    "    print(f\"  Within 5 minutes:     {within_5:.1f}%\")\n",
    "    print(f\"  Within 10 minutes:    {within_10:.1f}%\")\n",
    "    print(f\"  Within 15 minutes:    {within_15:.1f}%\")\n",
    "    print(f\"  Within 30 minutes:    {within_30:.1f}%\")\n",
    "    \n",
    "    return {\n",
    "        'mean': mean_err,\n",
    "        'median': median_err,\n",
    "        'std': std_err,\n",
    "        'max': max_err,\n",
    "        'within_0': within_0,\n",
    "        'within_1': within_1,\n",
    "        'within_5': within_5,\n",
    "        'within_10': within_10,\n",
    "        'within_15': within_15,\n",
    "        'within_30': within_30,\n",
    "        'predictions': pred_time,\n",
    "        'errors': diff_min\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    seed=42\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    keras.utils.set_random_seed(seed)\n",
    "\n",
    "    dir = f\"./images/multi\"\n",
    "    os.makedirs(dir, exist_ok=True)\n",
    "\n",
    "    # load data\n",
    "    X_train, y_train, X_val, y_val, X_test, y_test, _ = load_data(seed=42, easy=False)\n",
    "\n",
    "    # split y_test into hours and mintes arrays\n",
    "    y_test_split = list()\n",
    "    y_test_split.append(y_test[:, 0].reshape(-1, 1))\n",
    "    y_test_split.append(y_test[:, 1].reshape(-1, 1))\n",
    "\n",
    "    # load model\n",
    "    for curr_model in get_models():\n",
    "        model_path = f\"./saved_models/{curr_model}.keras\"\n",
    "        model = keras.models.load_model(model_path)\n",
    "\n",
    "        # make predictions\n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        \n",
    "\n",
    "        metrics = print_metrics(y_pred, y_test_split, curr_model)\n",
    "\n",
    "        errors = metrics['errors']\n",
    "\n",
    "\n",
    "        # convert split hours and minutes to decimal hours for plotting\n",
    "        true_decimal = to_decimal(y_test_split)\n",
    "        pred_decimal = to_decimal(y_pred)\n",
    "\n",
    "        # plot error histogram\n",
    "        plot_error_histogram(errors, model_name=curr_model, save_path=f\"{dir}/{curr_model}_error_histogram.png\")\n",
    "\n",
    "        # plot predictions vs true values\n",
    "        plot_predictions_vs_true(pred_decimal, true_decimal, model_name=curr_model, save_path=f\"{dir}/{curr_model}_pred_vs_true.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "idl2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
